{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projeto1_BrunoSantos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxf_QpVF4MV2"
      },
      "source": [
        "Aluno: Bruno Ricardo Pereira dos Santos Santos\n",
        "\n",
        "Nº USP: 10288640"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1QqWLug4MnQ",
        "outputId": "2f276851-2c9c-4afa-d183-f8b176e7476a"
      },
      "source": [
        "# Importando bibliotecas\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import *\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "!pip install plotly.express\n",
        "from plotly import graph_objs as go\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "Requirement already satisfied: plotly.express in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from plotly.express) (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from plotly.express) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from plotly.express) (1.4.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from plotly.express) (4.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotly.express) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from plotly.express) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->plotly.express) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->plotly.express) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->plotly.express) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.1.0->plotly.express) (1.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B06XFmLb__wd"
      },
      "source": [
        " # Identificação do problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ntSizF3AE1g"
      },
      "source": [
        "A base usada contém o texto de um SMS e a sua descrição, se é um spam ou não. O objetivo deste projeto é analisar e criar um modelo para classificação de textos de SMS.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgCiXIXq4Mvj"
      },
      "source": [
        "dataset = pd.read_excel('/content/drive/MyDrive/graduação/mineracao_dados_nao_estruturados/SMSSpamCollection.xlsx')\n",
        "dataset\n",
        "\n",
        "dataset['text'] = dataset['text'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUiDCLDbAwvZ"
      },
      "source": [
        "# Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqfUHGyDE4be"
      },
      "source": [
        "## Modelo bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQnSELPAysB"
      },
      "source": [
        "# remoção de pontuacao e stopwords\n",
        "\n",
        "def remove_stopwords(text,lang,domain_stopwords=[]):\n",
        "  \n",
        "  stop_words = nltk.corpus.stopwords.words(lang) # lang='portuguese' or lang='english'\n",
        "  \n",
        "  s = str(text).lower() # tudo para caixa baixa\n",
        "  table = str.maketrans({key: None for key in string.punctuation})\n",
        "  s = s.translate(table) # remove pontuacao\n",
        "  tokens = word_tokenize(s) #obtem tokens\n",
        "  v = [i for i in tokens if not i in stop_words and not i in domain_stopwords and not i.isdigit()] # remove stopwords\n",
        "  s = \"\"\n",
        "  for token in v:\n",
        "    s += token+\" \"\n",
        "  return s.strip()\n",
        "\n",
        "# stemming\n",
        "def stemming(text,lang):\n",
        "  \n",
        "  stemmer = PorterStemmer() # stemming para ingles\n",
        "  \n",
        "  if lang=='portuguese':\n",
        "    stemmer = nltk.stem.RSLPStemmer() # stemming para portuguese\n",
        "    \n",
        "  tokens = word_tokenize(text) #obtem tokens\n",
        "  \n",
        "  sentence_stem = ''\n",
        "  doc_text_stems = [stemmer.stem(i) for i in tokens]\n",
        "  for stem in doc_text_stems:\n",
        "    sentence_stem += stem+\" \"\n",
        "    \n",
        "  return sentence_stem.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "RomBBXmTDEoG",
        "outputId": "26280d76-3a2a-483f-a463-7dfec472f7d0"
      },
      "source": [
        "# Bag of Words com refinamento: ponderação por TF-IDF\n",
        "def compute_vsm_tfidf(dataset,lang,domain_stopwords=[]):\n",
        "  \n",
        "  d = []\n",
        "  for index,row in dataset.iterrows():\n",
        "    text = row['text'] #texto do evento\n",
        "    text2 = remove_stopwords(text, lang,domain_stopwords)\n",
        "    text3 = stemming(text2, lang)\n",
        "    d.append(text3)\n",
        "  matrix = TfidfVectorizer()\n",
        "  X = matrix.fit_transform(d)\n",
        "  \n",
        "  tfidf_vect_df = pd.DataFrame(X.todense(), columns=matrix.get_feature_names())\n",
        "\n",
        "  return tfidf_vect_df\n",
        "\n",
        "\n",
        "vsm = compute_vsm_tfidf(dataset,'english')\n",
        "vsm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0089mi</th>\n",
              "      <th>0776xxxxxxx</th>\n",
              "      <th>077xxx</th>\n",
              "      <th>0789xxxxxxx</th>\n",
              "      <th>0796xxxxxx</th>\n",
              "      <th>07xxxxxxxxx</th>\n",
              "      <th>08452810075over18</th>\n",
              "      <th>08700621170150p</th>\n",
              "      <th>08701417012150p</th>\n",
              "      <th>08702840625comuk</th>\n",
              "      <th>08704439680tsc</th>\n",
              "      <th>0870737910216yr</th>\n",
              "      <th>0870k</th>\n",
              "      <th>087123002209am7pm</th>\n",
              "      <th>08712460324nat</th>\n",
              "      <th>0871277810710pmin</th>\n",
              "      <th>0871277810910pmin</th>\n",
              "      <th>087143423992stop</th>\n",
              "      <th>087147123779am7pm</th>\n",
              "      <th>08717890890â</th>\n",
              "      <th>08718726270150gbpmtmsg18</th>\n",
              "      <th>09065171142stopsms08</th>\n",
              "      <th>09065171142stopsms08718727870150ppm</th>\n",
              "      <th>09066649731from</th>\n",
              "      <th>0anetwork</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>10000</th>\n",
              "      <th>100000</th>\n",
              "      <th>1000call</th>\n",
              "      <th>100psm</th>\n",
              "      <th>101mega</th>\n",
              "      <th>10am</th>\n",
              "      <th>10am7pm</th>\n",
              "      <th>10am9pm</th>\n",
              "      <th>10k</th>\n",
              "      <th>10p</th>\n",
              "      <th>10pmin</th>\n",
              "      <th>10ppm</th>\n",
              "      <th>...</th>\n",
              "      <th>youthat</th>\n",
              "      <th>youto</th>\n",
              "      <th>youuuuu</th>\n",
              "      <th>youv</th>\n",
              "      <th>youwanna</th>\n",
              "      <th>youwhen</th>\n",
              "      <th>youâ</th>\n",
              "      <th>yovil</th>\n",
              "      <th>yowif</th>\n",
              "      <th>yoyyooo</th>\n",
              "      <th>yr</th>\n",
              "      <th>ystrdayic</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yummmm</th>\n",
              "      <th>yun</th>\n",
              "      <th>yunni</th>\n",
              "      <th>yuo</th>\n",
              "      <th>yuou</th>\n",
              "      <th>yup</th>\n",
              "      <th>yupz</th>\n",
              "      <th>ywhere</th>\n",
              "      <th>zac</th>\n",
              "      <th>zaher</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zebra</th>\n",
              "      <th>zed</th>\n",
              "      <th>zero</th>\n",
              "      <th>zhong</th>\n",
              "      <th>zindgi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zogtoriu</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zouk</th>\n",
              "      <th>zyada</th>\n",
              "      <th>¾ã</th>\n",
              "      <th>ã¼</th>\n",
              "      <th>ã¼ll</th>\n",
              "      <th>ãœ</th>\n",
              "      <th>ãœll</th>\n",
              "      <th>œharri</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.247075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.289146</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386368</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5572</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5573</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5574 rows × 7593 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0089mi  0776xxxxxxx  077xxx  0789xxxxxxx  ...  ã¼ll   ãœ  ãœll  œharri\n",
              "0        0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "1        0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "2        0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "3        0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "4        0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "...      ...          ...     ...          ...  ...   ...  ...   ...     ...\n",
              "5569     0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "5570     0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "5571     0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "5572     0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "5573     0.0          0.0     0.0          0.0  ...   0.0  0.0   0.0     0.0\n",
              "\n",
              "[5574 rows x 7593 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxbW3lvmI5kn"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I2BpfetSu-L"
      },
      "source": [
        "Tendo em vista que nossa base de dados não apresenta em sua maior parte: \n",
        "\n",
        "- Textos muito complexos\n",
        "- Palavras com mais de um sentido\n",
        "- Palavras que invertem o sentido da sentença\n",
        "\n",
        "Não é necessário usar uma Word Embedding mais robusta como o ELMO ou o BERT para obter um resultado satisfatório, podemos usar uma word Embedding estática. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-05j67jjMxZ2",
        "outputId": "dff0440a-7d06-4902-b973-7d5c77546073"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-02 23:04:34--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.89.37\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.89.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2DKtqIgMz6Z",
        "outputId": "61554cab-ea46-4b93-8a68-66325031b61f"
      },
      "source": [
        "!pip install gensim\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nGEwYg7M2db"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lNAs7ivI6dd"
      },
      "source": [
        "df_w2v_train, df_w2v_test = train_test_split(dataset, test_size=0.30, random_state=42, stratify=dataset.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEqYZRS9hPz-",
        "outputId": "6ce68d41-56d5-497c-db79-b372ee294db3"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk import download\n",
        "download('stopwords')  # Download stopwords list.\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(sentence):\n",
        "    return [w for w in sentence.lower().split() if w not in stop_words]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdHxxh47VPwn"
      },
      "source": [
        "doc_embeddings = []\n",
        "for index,row in df_w2v_train.iterrows():\n",
        "  #print(row['OriginalTweet'])\n",
        "  sentence = preprocess(row['text'])\n",
        "  #print(sentence)\n",
        "  L = []\n",
        "  for token in sentence:\n",
        "    try:\n",
        "      #print(token,word2vec[token])\n",
        "      L.append(word2vec[token])\n",
        "    except:\n",
        "      1\n",
        "  if len(L) > 0: tweet_vec = np.mean(np.array(L),axis=0)\n",
        "  else: tweet_vec = np.zeros(300)\n",
        "  doc_embeddings.append(tweet_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xbvsKNgVSQ9",
        "outputId": "86c31cb7-5cc2-468f-dc06-36bc3701afcd"
      },
      "source": [
        "X_w2v_train = np.array(doc_embeddings)\n",
        "y_w2v_train = df_w2v_train.target.to_list()\n",
        "X_w2v_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3901, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "l6GTOyPmVSTW",
        "outputId": "30e4af38-c169-43fd-c077-b43e99dd4efc"
      },
      "source": [
        "pd.DataFrame(X_w2v_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.067671</td>\n",
              "      <td>-0.002075</td>\n",
              "      <td>0.154088</td>\n",
              "      <td>0.229597</td>\n",
              "      <td>-0.057103</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.101074</td>\n",
              "      <td>-0.101353</td>\n",
              "      <td>0.070304</td>\n",
              "      <td>0.048741</td>\n",
              "      <td>-0.071184</td>\n",
              "      <td>-0.232701</td>\n",
              "      <td>-0.092721</td>\n",
              "      <td>-0.035191</td>\n",
              "      <td>-0.062273</td>\n",
              "      <td>0.205497</td>\n",
              "      <td>0.113491</td>\n",
              "      <td>0.072353</td>\n",
              "      <td>-0.023333</td>\n",
              "      <td>-0.086914</td>\n",
              "      <td>-0.034110</td>\n",
              "      <td>0.061611</td>\n",
              "      <td>0.212472</td>\n",
              "      <td>0.079520</td>\n",
              "      <td>0.072043</td>\n",
              "      <td>0.068464</td>\n",
              "      <td>-0.043736</td>\n",
              "      <td>0.134975</td>\n",
              "      <td>-0.055725</td>\n",
              "      <td>-0.047538</td>\n",
              "      <td>-0.014186</td>\n",
              "      <td>0.148211</td>\n",
              "      <td>-0.014784</td>\n",
              "      <td>-0.092861</td>\n",
              "      <td>-0.121443</td>\n",
              "      <td>-0.056745</td>\n",
              "      <td>0.025495</td>\n",
              "      <td>0.009905</td>\n",
              "      <td>0.013048</td>\n",
              "      <td>0.015520</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.073696</td>\n",
              "      <td>0.096645</td>\n",
              "      <td>0.060704</td>\n",
              "      <td>-0.074812</td>\n",
              "      <td>0.004185</td>\n",
              "      <td>0.052804</td>\n",
              "      <td>-0.120640</td>\n",
              "      <td>0.016615</td>\n",
              "      <td>0.027902</td>\n",
              "      <td>0.019741</td>\n",
              "      <td>-0.014230</td>\n",
              "      <td>0.178667</td>\n",
              "      <td>0.107030</td>\n",
              "      <td>0.002241</td>\n",
              "      <td>0.125907</td>\n",
              "      <td>-0.100359</td>\n",
              "      <td>-0.071058</td>\n",
              "      <td>-0.071217</td>\n",
              "      <td>-0.087716</td>\n",
              "      <td>0.077881</td>\n",
              "      <td>-0.020996</td>\n",
              "      <td>-0.030829</td>\n",
              "      <td>-0.016009</td>\n",
              "      <td>0.103289</td>\n",
              "      <td>-0.014526</td>\n",
              "      <td>0.013236</td>\n",
              "      <td>-0.098430</td>\n",
              "      <td>0.020473</td>\n",
              "      <td>0.007690</td>\n",
              "      <td>0.025984</td>\n",
              "      <td>0.073172</td>\n",
              "      <td>0.191267</td>\n",
              "      <td>-0.124233</td>\n",
              "      <td>0.088693</td>\n",
              "      <td>-0.049997</td>\n",
              "      <td>-0.209612</td>\n",
              "      <td>0.004185</td>\n",
              "      <td>-0.013088</td>\n",
              "      <td>-0.020721</td>\n",
              "      <td>0.013532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.009888</td>\n",
              "      <td>0.053017</td>\n",
              "      <td>-0.014893</td>\n",
              "      <td>-0.068359</td>\n",
              "      <td>-0.029907</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.085205</td>\n",
              "      <td>-0.017090</td>\n",
              "      <td>0.027832</td>\n",
              "      <td>0.065674</td>\n",
              "      <td>-0.075439</td>\n",
              "      <td>-0.153809</td>\n",
              "      <td>0.027893</td>\n",
              "      <td>0.049377</td>\n",
              "      <td>-0.117065</td>\n",
              "      <td>0.109741</td>\n",
              "      <td>0.049042</td>\n",
              "      <td>0.212402</td>\n",
              "      <td>-0.116211</td>\n",
              "      <td>0.016602</td>\n",
              "      <td>-0.014160</td>\n",
              "      <td>0.072968</td>\n",
              "      <td>0.250488</td>\n",
              "      <td>-0.027405</td>\n",
              "      <td>0.291992</td>\n",
              "      <td>-0.021065</td>\n",
              "      <td>-0.014771</td>\n",
              "      <td>-0.009979</td>\n",
              "      <td>0.051514</td>\n",
              "      <td>0.054626</td>\n",
              "      <td>0.051880</td>\n",
              "      <td>-0.017029</td>\n",
              "      <td>0.007324</td>\n",
              "      <td>-0.002441</td>\n",
              "      <td>0.091187</td>\n",
              "      <td>0.027222</td>\n",
              "      <td>0.101562</td>\n",
              "      <td>-0.026070</td>\n",
              "      <td>-0.171204</td>\n",
              "      <td>0.043823</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090851</td>\n",
              "      <td>-0.084961</td>\n",
              "      <td>0.084473</td>\n",
              "      <td>0.052979</td>\n",
              "      <td>0.047302</td>\n",
              "      <td>0.359863</td>\n",
              "      <td>0.143555</td>\n",
              "      <td>-0.046631</td>\n",
              "      <td>-0.010254</td>\n",
              "      <td>0.083984</td>\n",
              "      <td>0.200195</td>\n",
              "      <td>-0.041992</td>\n",
              "      <td>0.145996</td>\n",
              "      <td>-0.045013</td>\n",
              "      <td>0.073669</td>\n",
              "      <td>-0.059204</td>\n",
              "      <td>0.003174</td>\n",
              "      <td>-0.142487</td>\n",
              "      <td>-0.150879</td>\n",
              "      <td>-0.064941</td>\n",
              "      <td>-0.132446</td>\n",
              "      <td>-0.025879</td>\n",
              "      <td>-0.096069</td>\n",
              "      <td>-0.065186</td>\n",
              "      <td>0.101929</td>\n",
              "      <td>0.035034</td>\n",
              "      <td>-0.052246</td>\n",
              "      <td>-0.069901</td>\n",
              "      <td>0.049286</td>\n",
              "      <td>0.000854</td>\n",
              "      <td>-0.012970</td>\n",
              "      <td>-0.052612</td>\n",
              "      <td>-0.090698</td>\n",
              "      <td>0.115479</td>\n",
              "      <td>-0.154541</td>\n",
              "      <td>-0.020874</td>\n",
              "      <td>0.092529</td>\n",
              "      <td>-0.115173</td>\n",
              "      <td>0.066711</td>\n",
              "      <td>0.026489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.028809</td>\n",
              "      <td>0.020508</td>\n",
              "      <td>0.122314</td>\n",
              "      <td>0.075562</td>\n",
              "      <td>-0.157837</td>\n",
              "      <td>0.182617</td>\n",
              "      <td>0.058716</td>\n",
              "      <td>-0.056410</td>\n",
              "      <td>0.262207</td>\n",
              "      <td>0.100342</td>\n",
              "      <td>-0.143799</td>\n",
              "      <td>-0.317383</td>\n",
              "      <td>-0.172974</td>\n",
              "      <td>-0.075745</td>\n",
              "      <td>-0.016541</td>\n",
              "      <td>0.253418</td>\n",
              "      <td>0.028809</td>\n",
              "      <td>0.043701</td>\n",
              "      <td>-0.075989</td>\n",
              "      <td>0.080078</td>\n",
              "      <td>-0.198730</td>\n",
              "      <td>0.079590</td>\n",
              "      <td>0.177246</td>\n",
              "      <td>-0.108185</td>\n",
              "      <td>-0.023193</td>\n",
              "      <td>-0.013824</td>\n",
              "      <td>-0.161621</td>\n",
              "      <td>0.087158</td>\n",
              "      <td>-0.003357</td>\n",
              "      <td>-0.048035</td>\n",
              "      <td>0.006104</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>-0.204620</td>\n",
              "      <td>-0.161377</td>\n",
              "      <td>-0.100342</td>\n",
              "      <td>0.128418</td>\n",
              "      <td>-0.017090</td>\n",
              "      <td>-0.098877</td>\n",
              "      <td>0.096191</td>\n",
              "      <td>-0.134033</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021118</td>\n",
              "      <td>0.047852</td>\n",
              "      <td>-0.056641</td>\n",
              "      <td>0.034180</td>\n",
              "      <td>-0.003235</td>\n",
              "      <td>0.089844</td>\n",
              "      <td>-0.171631</td>\n",
              "      <td>-0.074829</td>\n",
              "      <td>0.198486</td>\n",
              "      <td>-0.191895</td>\n",
              "      <td>0.042480</td>\n",
              "      <td>0.067200</td>\n",
              "      <td>0.187988</td>\n",
              "      <td>0.069580</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>-0.133789</td>\n",
              "      <td>0.042542</td>\n",
              "      <td>-0.172363</td>\n",
              "      <td>-0.119598</td>\n",
              "      <td>0.085938</td>\n",
              "      <td>-0.079834</td>\n",
              "      <td>-0.026520</td>\n",
              "      <td>-0.020447</td>\n",
              "      <td>0.135742</td>\n",
              "      <td>0.100708</td>\n",
              "      <td>0.017822</td>\n",
              "      <td>-0.091919</td>\n",
              "      <td>-0.096436</td>\n",
              "      <td>0.153809</td>\n",
              "      <td>0.100098</td>\n",
              "      <td>-0.135498</td>\n",
              "      <td>0.096191</td>\n",
              "      <td>-0.048340</td>\n",
              "      <td>0.114746</td>\n",
              "      <td>-0.107544</td>\n",
              "      <td>-0.181519</td>\n",
              "      <td>-0.236816</td>\n",
              "      <td>-0.049927</td>\n",
              "      <td>-0.063837</td>\n",
              "      <td>0.000977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.053874</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>-0.021566</td>\n",
              "      <td>0.118001</td>\n",
              "      <td>-0.094564</td>\n",
              "      <td>0.043538</td>\n",
              "      <td>0.193848</td>\n",
              "      <td>-0.239583</td>\n",
              "      <td>-0.043294</td>\n",
              "      <td>0.176758</td>\n",
              "      <td>-0.014445</td>\n",
              "      <td>-0.019857</td>\n",
              "      <td>0.070028</td>\n",
              "      <td>-0.012533</td>\n",
              "      <td>-0.080566</td>\n",
              "      <td>0.107259</td>\n",
              "      <td>-0.037435</td>\n",
              "      <td>0.139974</td>\n",
              "      <td>0.053355</td>\n",
              "      <td>-0.102051</td>\n",
              "      <td>-0.095703</td>\n",
              "      <td>-0.011912</td>\n",
              "      <td>0.091777</td>\n",
              "      <td>-0.053385</td>\n",
              "      <td>0.128906</td>\n",
              "      <td>-0.027018</td>\n",
              "      <td>0.048950</td>\n",
              "      <td>0.101888</td>\n",
              "      <td>0.120605</td>\n",
              "      <td>-0.101237</td>\n",
              "      <td>-0.082845</td>\n",
              "      <td>0.190999</td>\n",
              "      <td>0.088521</td>\n",
              "      <td>0.041829</td>\n",
              "      <td>-0.090169</td>\n",
              "      <td>0.101481</td>\n",
              "      <td>0.001302</td>\n",
              "      <td>-0.076660</td>\n",
              "      <td>-0.007894</td>\n",
              "      <td>0.261312</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058512</td>\n",
              "      <td>-0.046387</td>\n",
              "      <td>-0.001139</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.044434</td>\n",
              "      <td>0.043050</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.009237</td>\n",
              "      <td>-0.056315</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.041911</td>\n",
              "      <td>0.081305</td>\n",
              "      <td>0.037109</td>\n",
              "      <td>0.107910</td>\n",
              "      <td>0.181641</td>\n",
              "      <td>-0.114176</td>\n",
              "      <td>-0.101807</td>\n",
              "      <td>-0.030477</td>\n",
              "      <td>-0.135905</td>\n",
              "      <td>-0.000081</td>\n",
              "      <td>0.108927</td>\n",
              "      <td>-0.031372</td>\n",
              "      <td>-0.064453</td>\n",
              "      <td>0.142741</td>\n",
              "      <td>-0.007650</td>\n",
              "      <td>-0.110189</td>\n",
              "      <td>-0.135986</td>\n",
              "      <td>0.083984</td>\n",
              "      <td>0.078776</td>\n",
              "      <td>0.020671</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>-0.015299</td>\n",
              "      <td>-0.144694</td>\n",
              "      <td>-0.179769</td>\n",
              "      <td>-0.016032</td>\n",
              "      <td>-0.097168</td>\n",
              "      <td>-0.027837</td>\n",
              "      <td>-0.047526</td>\n",
              "      <td>0.011230</td>\n",
              "      <td>0.012655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.193359</td>\n",
              "      <td>-0.004333</td>\n",
              "      <td>-0.032227</td>\n",
              "      <td>0.139648</td>\n",
              "      <td>-0.020264</td>\n",
              "      <td>-0.100098</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>-0.002060</td>\n",
              "      <td>0.152344</td>\n",
              "      <td>0.061279</td>\n",
              "      <td>-0.129883</td>\n",
              "      <td>-0.143555</td>\n",
              "      <td>-0.025024</td>\n",
              "      <td>0.131836</td>\n",
              "      <td>-0.109863</td>\n",
              "      <td>0.028809</td>\n",
              "      <td>0.027710</td>\n",
              "      <td>0.139648</td>\n",
              "      <td>-0.166992</td>\n",
              "      <td>-0.086426</td>\n",
              "      <td>-0.006805</td>\n",
              "      <td>-0.109863</td>\n",
              "      <td>0.062256</td>\n",
              "      <td>-0.057129</td>\n",
              "      <td>0.022339</td>\n",
              "      <td>0.050049</td>\n",
              "      <td>-0.092773</td>\n",
              "      <td>-0.033936</td>\n",
              "      <td>-0.020752</td>\n",
              "      <td>-0.218750</td>\n",
              "      <td>0.021606</td>\n",
              "      <td>0.022827</td>\n",
              "      <td>0.137695</td>\n",
              "      <td>-0.122070</td>\n",
              "      <td>0.050049</td>\n",
              "      <td>-0.118164</td>\n",
              "      <td>0.137695</td>\n",
              "      <td>-0.124023</td>\n",
              "      <td>0.043457</td>\n",
              "      <td>-0.060303</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045898</td>\n",
              "      <td>-0.081543</td>\n",
              "      <td>-0.135742</td>\n",
              "      <td>-0.005219</td>\n",
              "      <td>0.086426</td>\n",
              "      <td>0.091797</td>\n",
              "      <td>-0.028320</td>\n",
              "      <td>0.079590</td>\n",
              "      <td>0.002762</td>\n",
              "      <td>0.010498</td>\n",
              "      <td>0.222656</td>\n",
              "      <td>0.141602</td>\n",
              "      <td>-0.010254</td>\n",
              "      <td>0.183594</td>\n",
              "      <td>-0.005707</td>\n",
              "      <td>-0.023682</td>\n",
              "      <td>-0.117188</td>\n",
              "      <td>-0.048584</td>\n",
              "      <td>-0.068359</td>\n",
              "      <td>-0.195312</td>\n",
              "      <td>0.101074</td>\n",
              "      <td>-0.028809</td>\n",
              "      <td>0.048828</td>\n",
              "      <td>-0.022583</td>\n",
              "      <td>-0.065430</td>\n",
              "      <td>0.043457</td>\n",
              "      <td>-0.041260</td>\n",
              "      <td>0.057861</td>\n",
              "      <td>-0.045166</td>\n",
              "      <td>0.203125</td>\n",
              "      <td>-0.174805</td>\n",
              "      <td>-0.122559</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>-0.088867</td>\n",
              "      <td>-0.075684</td>\n",
              "      <td>0.078613</td>\n",
              "      <td>0.075195</td>\n",
              "      <td>0.052002</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>-0.006592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3896</th>\n",
              "      <td>-0.018480</td>\n",
              "      <td>0.035795</td>\n",
              "      <td>-0.023838</td>\n",
              "      <td>0.066830</td>\n",
              "      <td>-0.079909</td>\n",
              "      <td>0.118455</td>\n",
              "      <td>0.094905</td>\n",
              "      <td>0.033818</td>\n",
              "      <td>0.089637</td>\n",
              "      <td>-0.018386</td>\n",
              "      <td>-0.021575</td>\n",
              "      <td>-0.074942</td>\n",
              "      <td>-0.048941</td>\n",
              "      <td>-0.014137</td>\n",
              "      <td>-0.091011</td>\n",
              "      <td>0.123345</td>\n",
              "      <td>0.033137</td>\n",
              "      <td>0.102361</td>\n",
              "      <td>-0.014454</td>\n",
              "      <td>-0.121712</td>\n",
              "      <td>0.024940</td>\n",
              "      <td>-0.042529</td>\n",
              "      <td>0.098234</td>\n",
              "      <td>0.047077</td>\n",
              "      <td>-0.016893</td>\n",
              "      <td>0.010813</td>\n",
              "      <td>-0.105938</td>\n",
              "      <td>0.087703</td>\n",
              "      <td>0.045606</td>\n",
              "      <td>-0.051255</td>\n",
              "      <td>0.012198</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.087247</td>\n",
              "      <td>-0.025228</td>\n",
              "      <td>-0.074573</td>\n",
              "      <td>-0.129540</td>\n",
              "      <td>0.117901</td>\n",
              "      <td>-0.038044</td>\n",
              "      <td>0.015564</td>\n",
              "      <td>0.026649</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027006</td>\n",
              "      <td>-0.000587</td>\n",
              "      <td>-0.093919</td>\n",
              "      <td>-0.041443</td>\n",
              "      <td>0.057040</td>\n",
              "      <td>0.112002</td>\n",
              "      <td>-0.095328</td>\n",
              "      <td>0.042250</td>\n",
              "      <td>-0.068758</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.079524</td>\n",
              "      <td>0.134371</td>\n",
              "      <td>0.124133</td>\n",
              "      <td>0.063275</td>\n",
              "      <td>-0.102464</td>\n",
              "      <td>-0.060376</td>\n",
              "      <td>-0.121418</td>\n",
              "      <td>-0.070521</td>\n",
              "      <td>0.043842</td>\n",
              "      <td>-0.036374</td>\n",
              "      <td>0.030611</td>\n",
              "      <td>-0.050255</td>\n",
              "      <td>0.061213</td>\n",
              "      <td>0.075646</td>\n",
              "      <td>0.024186</td>\n",
              "      <td>-0.046182</td>\n",
              "      <td>0.025794</td>\n",
              "      <td>0.011867</td>\n",
              "      <td>-0.014462</td>\n",
              "      <td>-0.018159</td>\n",
              "      <td>0.120774</td>\n",
              "      <td>-0.055565</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>-0.043490</td>\n",
              "      <td>-0.049636</td>\n",
              "      <td>-0.039739</td>\n",
              "      <td>-0.146679</td>\n",
              "      <td>-0.078510</td>\n",
              "      <td>0.005709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3897</th>\n",
              "      <td>0.089355</td>\n",
              "      <td>-0.010579</td>\n",
              "      <td>0.042155</td>\n",
              "      <td>0.134115</td>\n",
              "      <td>0.098470</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>0.058757</td>\n",
              "      <td>-0.163411</td>\n",
              "      <td>0.083984</td>\n",
              "      <td>0.063924</td>\n",
              "      <td>-0.005147</td>\n",
              "      <td>-0.057861</td>\n",
              "      <td>-0.115234</td>\n",
              "      <td>0.096680</td>\n",
              "      <td>-0.102089</td>\n",
              "      <td>-0.032837</td>\n",
              "      <td>0.149902</td>\n",
              "      <td>0.119466</td>\n",
              "      <td>0.203776</td>\n",
              "      <td>0.078776</td>\n",
              "      <td>-0.162109</td>\n",
              "      <td>0.058350</td>\n",
              "      <td>0.047597</td>\n",
              "      <td>0.068848</td>\n",
              "      <td>0.006592</td>\n",
              "      <td>0.094116</td>\n",
              "      <td>-0.071976</td>\n",
              "      <td>-0.052734</td>\n",
              "      <td>-0.064372</td>\n",
              "      <td>-0.029277</td>\n",
              "      <td>-0.064128</td>\n",
              "      <td>0.141195</td>\n",
              "      <td>-0.078776</td>\n",
              "      <td>-0.089844</td>\n",
              "      <td>-0.078125</td>\n",
              "      <td>-0.116435</td>\n",
              "      <td>-0.031413</td>\n",
              "      <td>-0.017110</td>\n",
              "      <td>-0.029053</td>\n",
              "      <td>0.023275</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101074</td>\n",
              "      <td>-0.023438</td>\n",
              "      <td>-0.090169</td>\n",
              "      <td>0.077342</td>\n",
              "      <td>0.013875</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.063212</td>\n",
              "      <td>-0.012370</td>\n",
              "      <td>-0.107463</td>\n",
              "      <td>0.040527</td>\n",
              "      <td>0.037669</td>\n",
              "      <td>0.105469</td>\n",
              "      <td>0.171875</td>\n",
              "      <td>0.035116</td>\n",
              "      <td>0.100423</td>\n",
              "      <td>-0.199382</td>\n",
              "      <td>-0.183665</td>\n",
              "      <td>0.018344</td>\n",
              "      <td>-0.026286</td>\n",
              "      <td>-0.086263</td>\n",
              "      <td>0.055420</td>\n",
              "      <td>-0.044759</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>0.094401</td>\n",
              "      <td>-0.022217</td>\n",
              "      <td>-0.038656</td>\n",
              "      <td>0.062012</td>\n",
              "      <td>-0.053223</td>\n",
              "      <td>0.076253</td>\n",
              "      <td>0.221761</td>\n",
              "      <td>-0.072103</td>\n",
              "      <td>0.163818</td>\n",
              "      <td>-0.076363</td>\n",
              "      <td>0.045776</td>\n",
              "      <td>-0.013265</td>\n",
              "      <td>0.068604</td>\n",
              "      <td>-0.160645</td>\n",
              "      <td>-0.054199</td>\n",
              "      <td>0.070353</td>\n",
              "      <td>-0.022786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3898</th>\n",
              "      <td>-0.015951</td>\n",
              "      <td>0.066447</td>\n",
              "      <td>0.146810</td>\n",
              "      <td>0.162435</td>\n",
              "      <td>0.024536</td>\n",
              "      <td>-0.055827</td>\n",
              "      <td>-0.085124</td>\n",
              "      <td>-0.037287</td>\n",
              "      <td>0.139323</td>\n",
              "      <td>0.127279</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>-0.015137</td>\n",
              "      <td>-0.081217</td>\n",
              "      <td>0.071320</td>\n",
              "      <td>-0.065267</td>\n",
              "      <td>0.198568</td>\n",
              "      <td>0.026774</td>\n",
              "      <td>0.090739</td>\n",
              "      <td>0.114990</td>\n",
              "      <td>0.024414</td>\n",
              "      <td>-0.116048</td>\n",
              "      <td>0.097819</td>\n",
              "      <td>0.158875</td>\n",
              "      <td>0.042643</td>\n",
              "      <td>-0.264648</td>\n",
              "      <td>-0.049805</td>\n",
              "      <td>-0.078125</td>\n",
              "      <td>-0.010376</td>\n",
              "      <td>0.020182</td>\n",
              "      <td>-0.058472</td>\n",
              "      <td>0.070109</td>\n",
              "      <td>0.245605</td>\n",
              "      <td>-0.071615</td>\n",
              "      <td>-0.182292</td>\n",
              "      <td>0.009644</td>\n",
              "      <td>0.131185</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.058512</td>\n",
              "      <td>-0.011393</td>\n",
              "      <td>0.040324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116618</td>\n",
              "      <td>0.164632</td>\n",
              "      <td>0.011556</td>\n",
              "      <td>-0.075053</td>\n",
              "      <td>0.070150</td>\n",
              "      <td>0.089803</td>\n",
              "      <td>0.011978</td>\n",
              "      <td>0.061686</td>\n",
              "      <td>0.097087</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>-0.037964</td>\n",
              "      <td>0.057943</td>\n",
              "      <td>0.223307</td>\n",
              "      <td>-0.036519</td>\n",
              "      <td>0.078613</td>\n",
              "      <td>0.006755</td>\n",
              "      <td>-0.061523</td>\n",
              "      <td>-0.102051</td>\n",
              "      <td>-0.248332</td>\n",
              "      <td>0.259440</td>\n",
              "      <td>-0.012126</td>\n",
              "      <td>-0.013835</td>\n",
              "      <td>0.076660</td>\n",
              "      <td>-0.017904</td>\n",
              "      <td>-0.019979</td>\n",
              "      <td>0.056803</td>\n",
              "      <td>-0.027100</td>\n",
              "      <td>0.029907</td>\n",
              "      <td>-0.058202</td>\n",
              "      <td>0.071370</td>\n",
              "      <td>0.184896</td>\n",
              "      <td>0.045166</td>\n",
              "      <td>-0.027974</td>\n",
              "      <td>-0.118937</td>\n",
              "      <td>-0.089233</td>\n",
              "      <td>-0.073975</td>\n",
              "      <td>-0.198730</td>\n",
              "      <td>-0.195150</td>\n",
              "      <td>0.105632</td>\n",
              "      <td>-0.016276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3899</th>\n",
              "      <td>-0.035812</td>\n",
              "      <td>-0.009743</td>\n",
              "      <td>-0.118286</td>\n",
              "      <td>0.186768</td>\n",
              "      <td>-0.038269</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>-0.151123</td>\n",
              "      <td>-0.093201</td>\n",
              "      <td>0.063721</td>\n",
              "      <td>0.036804</td>\n",
              "      <td>-0.110657</td>\n",
              "      <td>-0.069336</td>\n",
              "      <td>-0.147461</td>\n",
              "      <td>-0.032227</td>\n",
              "      <td>-0.098633</td>\n",
              "      <td>-0.077393</td>\n",
              "      <td>0.212891</td>\n",
              "      <td>0.127075</td>\n",
              "      <td>-0.084717</td>\n",
              "      <td>-0.108887</td>\n",
              "      <td>-0.122803</td>\n",
              "      <td>0.050659</td>\n",
              "      <td>0.103516</td>\n",
              "      <td>-0.156250</td>\n",
              "      <td>-0.218262</td>\n",
              "      <td>0.175293</td>\n",
              "      <td>-0.104492</td>\n",
              "      <td>0.264648</td>\n",
              "      <td>-0.014328</td>\n",
              "      <td>0.020508</td>\n",
              "      <td>0.179932</td>\n",
              "      <td>-0.007324</td>\n",
              "      <td>-0.063354</td>\n",
              "      <td>-0.145508</td>\n",
              "      <td>-0.244141</td>\n",
              "      <td>0.118652</td>\n",
              "      <td>-0.110352</td>\n",
              "      <td>0.098511</td>\n",
              "      <td>0.012451</td>\n",
              "      <td>0.026855</td>\n",
              "      <td>...</td>\n",
              "      <td>0.321777</td>\n",
              "      <td>-0.145508</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>-0.133057</td>\n",
              "      <td>0.082275</td>\n",
              "      <td>-0.016678</td>\n",
              "      <td>-0.032227</td>\n",
              "      <td>0.117188</td>\n",
              "      <td>0.061157</td>\n",
              "      <td>-0.098877</td>\n",
              "      <td>0.021240</td>\n",
              "      <td>0.039917</td>\n",
              "      <td>0.069824</td>\n",
              "      <td>0.069214</td>\n",
              "      <td>0.087769</td>\n",
              "      <td>0.000854</td>\n",
              "      <td>-0.057617</td>\n",
              "      <td>-0.022339</td>\n",
              "      <td>-0.159180</td>\n",
              "      <td>0.194092</td>\n",
              "      <td>-0.078979</td>\n",
              "      <td>0.095947</td>\n",
              "      <td>-0.002686</td>\n",
              "      <td>0.080566</td>\n",
              "      <td>-0.057709</td>\n",
              "      <td>0.047241</td>\n",
              "      <td>-0.078033</td>\n",
              "      <td>-0.065796</td>\n",
              "      <td>0.073853</td>\n",
              "      <td>0.020432</td>\n",
              "      <td>-0.091248</td>\n",
              "      <td>-0.008179</td>\n",
              "      <td>0.046913</td>\n",
              "      <td>0.092407</td>\n",
              "      <td>0.102661</td>\n",
              "      <td>-0.279785</td>\n",
              "      <td>-0.251465</td>\n",
              "      <td>-0.008789</td>\n",
              "      <td>-0.156738</td>\n",
              "      <td>-0.040771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3900</th>\n",
              "      <td>0.125651</td>\n",
              "      <td>0.082316</td>\n",
              "      <td>0.039958</td>\n",
              "      <td>0.043538</td>\n",
              "      <td>-0.103556</td>\n",
              "      <td>-0.097483</td>\n",
              "      <td>-0.107117</td>\n",
              "      <td>-0.080363</td>\n",
              "      <td>-0.002848</td>\n",
              "      <td>0.031779</td>\n",
              "      <td>-0.076538</td>\n",
              "      <td>-0.077847</td>\n",
              "      <td>-0.120443</td>\n",
              "      <td>0.114929</td>\n",
              "      <td>-0.201090</td>\n",
              "      <td>0.093170</td>\n",
              "      <td>-0.169607</td>\n",
              "      <td>0.109782</td>\n",
              "      <td>-0.106567</td>\n",
              "      <td>-0.017660</td>\n",
              "      <td>-0.106445</td>\n",
              "      <td>-0.002930</td>\n",
              "      <td>0.109588</td>\n",
              "      <td>-0.006714</td>\n",
              "      <td>0.098307</td>\n",
              "      <td>-0.040952</td>\n",
              "      <td>-0.234049</td>\n",
              "      <td>-0.007609</td>\n",
              "      <td>-0.049377</td>\n",
              "      <td>0.041026</td>\n",
              "      <td>-0.001953</td>\n",
              "      <td>0.077423</td>\n",
              "      <td>-0.029073</td>\n",
              "      <td>0.105225</td>\n",
              "      <td>-0.138468</td>\n",
              "      <td>-0.008097</td>\n",
              "      <td>-0.090698</td>\n",
              "      <td>-0.091736</td>\n",
              "      <td>0.116760</td>\n",
              "      <td>0.070923</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006307</td>\n",
              "      <td>0.064031</td>\n",
              "      <td>0.135742</td>\n",
              "      <td>0.029541</td>\n",
              "      <td>0.131673</td>\n",
              "      <td>0.054769</td>\n",
              "      <td>-0.092468</td>\n",
              "      <td>0.127889</td>\n",
              "      <td>-0.056091</td>\n",
              "      <td>-0.060547</td>\n",
              "      <td>-0.200623</td>\n",
              "      <td>-0.037760</td>\n",
              "      <td>0.268677</td>\n",
              "      <td>-0.005819</td>\n",
              "      <td>-0.028971</td>\n",
              "      <td>0.044271</td>\n",
              "      <td>0.104085</td>\n",
              "      <td>-0.057231</td>\n",
              "      <td>-0.110067</td>\n",
              "      <td>0.121033</td>\n",
              "      <td>-0.029399</td>\n",
              "      <td>0.110311</td>\n",
              "      <td>0.240561</td>\n",
              "      <td>0.012899</td>\n",
              "      <td>0.071615</td>\n",
              "      <td>-0.106445</td>\n",
              "      <td>-0.104818</td>\n",
              "      <td>-0.086528</td>\n",
              "      <td>0.062419</td>\n",
              "      <td>0.177205</td>\n",
              "      <td>-0.046519</td>\n",
              "      <td>0.134603</td>\n",
              "      <td>-0.105062</td>\n",
              "      <td>-0.078206</td>\n",
              "      <td>0.005493</td>\n",
              "      <td>-0.023397</td>\n",
              "      <td>-0.127950</td>\n",
              "      <td>-0.143555</td>\n",
              "      <td>-0.020186</td>\n",
              "      <td>0.137288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3901 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    ...       297       298       299\n",
              "0     0.067671 -0.002075  0.154088  ... -0.013088 -0.020721  0.013532\n",
              "1     0.009888  0.053017 -0.014893  ... -0.115173  0.066711  0.026489\n",
              "2    -0.028809  0.020508  0.122314  ... -0.049927 -0.063837  0.000977\n",
              "3     0.053874  0.004395 -0.021566  ... -0.047526  0.011230  0.012655\n",
              "4     0.193359 -0.004333 -0.032227  ...  0.052002  0.027588 -0.006592\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "3896 -0.018480  0.035795 -0.023838  ... -0.146679 -0.078510  0.005709\n",
              "3897  0.089355 -0.010579  0.042155  ... -0.054199  0.070353 -0.022786\n",
              "3898 -0.015951  0.066447  0.146810  ... -0.195150  0.105632 -0.016276\n",
              "3899 -0.035812 -0.009743 -0.118286  ... -0.008789 -0.156738 -0.040771\n",
              "3900  0.125651  0.082316  0.039958  ... -0.143555 -0.020186  0.137288\n",
              "\n",
              "[3901 rows x 300 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea8pXhicVSVo"
      },
      "source": [
        "doc_embeddings = []\n",
        "for index,row in df_w2v_test.iterrows():\n",
        "  sentence = preprocess(row['text'])\n",
        "  L = []\n",
        "  for token in sentence:\n",
        "    try:\n",
        "      #print(token,word2vec[token])\n",
        "      L.append(word2vec[token])\n",
        "    except:\n",
        "      1\n",
        "  if len(L) > 0: tweet_vec = np.mean(np.array(L),axis=0)\n",
        "  else: tweet_vec = np.zeros(300)\n",
        "  doc_embeddings.append(tweet_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-CndsmEVSYN",
        "outputId": "d8b6e686-93a9-46c3-a15b-c6707f979275"
      },
      "source": [
        "X_w2v_test = np.array(doc_embeddings)\n",
        "y_w2v_test = df_w2v_test.target.to_list()\n",
        "X_w2v_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1673, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFVDOFeZYv0p"
      },
      "source": [
        "# Extração de padrões (ML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-n_ncoLY6WP"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVr8AhqcIjhi",
        "outputId": "2a7f4035-8e13-4aa6-fb9f-735e2f8a6b3e"
      },
      "source": [
        "# Preparando dados para classificador kNN\n",
        "X = np.array(vsm)\n",
        "length = np.sqrt((X**2).sum(axis=1))[:,None]\n",
        "X_bag = X / (length+0.00001)\n",
        "\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5574, 7593)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MekJ6r_dVAqz"
      },
      "source": [
        "Y_bag = dataset['target'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkYXu3juVEiK"
      },
      "source": [
        "X_bag_train, X_bag_test, y_bag_train, y_bag_test = train_test_split(X_bag, Y_bag, test_size=0.30, random_state=42, stratify = Y_bag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt95vX38VGhq"
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_bag_train, y_bag_train)\n",
        "\n",
        "neigh.score(X_bag_test,y_bag_test)\n",
        "\n",
        "predictions_bag = list(neigh.predict(X_bag_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_llbON3-SksY",
        "outputId": "72ec37c0-1adf-4283-a7ca-442ee7e8a572"
      },
      "source": [
        "\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_bag_test, predictions_bag)))\n",
        "print('Precision score: {}'.format(precision_score(y_bag_test, predictions_bag,pos_label='spam')))\n",
        "print('Recall score: {}'.format(recall_score(y_bag_test, predictions_bag,pos_label='spam')))\n",
        "print('F1 score: {}'.format(f1_score(y_bag_test, predictions_bag,pos_label='spam')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.9282725642558278\n",
            "Precision score: 1.0\n",
            "Recall score: 0.4642857142857143\n",
            "F1 score: 0.6341463414634146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVYh-VFS_c1d",
        "outputId": "0e4d0ecb-3496-4696-a939-7de6e63129f2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_bag_test,predictions_bag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1449,    0],\n",
              "       [ 120,  104]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akLQqCmGY8-i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cubNSnxzdhc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hnvmnNmY1q2"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEi6Q790VSap"
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_w2v_train, y_w2v_train)\n",
        "\n",
        "neigh.score(X_w2v_test,y_w2v_test)\n",
        "\n",
        "predictions_w2v = list(neigh.predict(X_w2v_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6NY6L4VRfSE",
        "outputId": "3cebe4fd-2257-4648-ca58-7d1cff2784cd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_w2v_test, predictions_w2v)))\n",
        "print('Precision score: {}'.format(precision_score(y_w2v_test, predictions_w2v,pos_label='spam')))\n",
        "print('Recall score: {}'.format(recall_score(y_w2v_test, predictions_w2v,pos_label='spam')))\n",
        "print('F1 score: {}'.format(f1_score(y_w2v_test, predictions_w2v,pos_label='spam')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.9563658099222953\n",
            "Precision score: 0.8007968127490039\n",
            "Recall score: 0.8973214285714286\n",
            "F1 score: 0.8463157894736842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHbkXxJw9YS-",
        "outputId": "d852467f-9d7c-4dc3-dfca-866fbf479ec2"
      },
      "source": [
        "confusion_matrix(y_w2v_test,predictions_w2v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1399,   50],\n",
              "       [  23,  201]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8V17rOwVnM9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMD2YXMqVc2t"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvgNVmLbl2jh"
      },
      "source": [
        "Mesmo obtendo um modelo satisfatório usando Word2Vec, testaremos um modelo que demanda mais poder computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8Zzb3kFVSf6",
        "outputId": "70e5a736-a42c-40ca-ac21-b0a5e1f22800"
      },
      "source": [
        "#!pip install ktrain\n",
        "import keras\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.28.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: transformers<=4.10.3,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.10.3)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.88.0)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.96)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (3.0.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Requirement already satisfied: keras-transformer>=0.39.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.39.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.12.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.28.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.7.0)\n",
            "Requirement already satisfied: keras-self-attention>=0.50.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head>=0.28.0->keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.50.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers<=4.10.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.10.3,>=4.0.0->ktrain) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.3,>=4.0.0->ktrain) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "RQmZYd20VmzN",
        "outputId": "e4d6111d-2821-4e2a-d9e7-eb6044011475"
      },
      "source": [
        "(x_bert_train, y_bert_train), (x_bert_test, y_bert_test), preproc = text.texts_from_df(dataset, \n",
        "                                                                   'text',\n",
        "                                                                   label_columns='target',\n",
        "                                                                   maxlen=64, \n",
        "                                                                   max_features=10000,\n",
        "                                                                   preprocess_mode='bert',\n",
        "                                                                   lang=None,\n",
        "                                                                   val_pct = 0.3,\n",
        "                                                                   random_state=42\n",
        "                                                                   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham', 'spam']\n",
            "      ham  spam\n",
            "4977  1.0   0.0\n",
            "650   0.0   1.0\n",
            "5184  1.0   0.0\n",
            "708   1.0   0.0\n",
            "3295  1.0   0.0\n",
            "['ham', 'spam']\n",
            "      ham  spam\n",
            "3690  1.0   0.0\n",
            "3527  1.0   0.0\n",
            "724   1.0   0.0\n",
            "3370  1.0   0.0\n",
            "468   1.0   0.0\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snvHB4wgVm13",
        "outputId": "48117a68-2bd1-4616-87ac-82d4b542d6ec"
      },
      "source": [
        "model = text.text_classifier('bert', (x_bert_train, y_bert_train) , preproc=preproc)\n",
        "classifier = ktrain.get_learner(model, \n",
        "                             train_data=(x_bert_train, y_bert_train), \n",
        "                             val_data=(x_bert_test, y_bert_test),\n",
        "                             batch_size=64\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 64\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "swE71uQPVm4e",
        "outputId": "e8fa393b-4c3c-4c88-cbb7-2363eddf9409"
      },
      "source": [
        "classifier.fit_onecycle(0.00002,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/5\n",
            "61/61 [==============================] - 3008s 49s/step - loss: 0.4402 - accuracy: 0.7765 - val_loss: 0.1162 - val_accuracy: 0.9809\n",
            "Epoch 2/5\n",
            "61/61 [==============================] - 2934s 48s/step - loss: 0.0542 - accuracy: 0.9859 - val_loss: 0.0286 - val_accuracy: 0.9934\n",
            "Epoch 3/5\n",
            "22/61 [=========>....................] - ETA: 27:59 - loss: 0.0248 - accuracy: 0.9922"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-534591c8d749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_onecycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.00002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mfit_onecycle\u001b[0;34m(self, lr, epochs, checkpoint_folder, cycle_momentum, max_momentum, min_momentum, class_weight, callbacks, steps_per_epoch, verbose)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                         steps_per_epoch=steps_per_epoch)\n\u001b[0m\u001b[1;32m    902\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lr, n_cycles, cycle_len, cycle_mult, lr_decay, checkpoint_folder, early_stopping, verbose, class_weight, callbacks, steps_per_epoch)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                   \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                   \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                   callbacks=kcallbacks)\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msgdr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYh_ZUoOVm7G",
        "outputId": "9db0f4d6-6359-4c91-ed71-d7dba9564ff2"
      },
      "source": [
        "resul = classifier.validate()\n",
        "resul"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1447\n",
            "           1       0.99      0.97      0.98       226\n",
            "\n",
            "    accuracy                           0.99      1673\n",
            "   macro avg       0.99      0.98      0.99      1673\n",
            "weighted avg       0.99      0.99      0.99      1673\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1445,    2],\n",
              "       [   7,  219]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1F5T35hVm9u"
      },
      "source": [
        "classifier_model = ktrain.get_predictor(classifier.model, preproc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IzM3aBaVnC7",
        "outputId": "ab1ded1e-2cc2-4687-97cf-3ab5faeb1fd0"
      },
      "source": [
        "classifier_model.save('/content/drive/MyDrive/graduação/mineracao_dados_nao_estruturados/my_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning:\n",
            "\n",
            "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1HVi8rVpS-R"
      },
      "source": [
        "# Pós - processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w7QrodwuW3t"
      },
      "source": [
        "- Acurácia: indica uma performance geral do modelo. Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
        "\n",
        "- Precisão: dentre todas as classificações de classe Positivo que o modelo fez, quantas estão corretas;\n",
        "\n",
        "- Recall: dentre todas as situações de classe Positivo como valor esperado, quantas estão corretas;\n",
        "\n",
        "- F1-Score: média harmônica entre precisão e recall.\n",
        "\n",
        "Ao receber spams em SMS, é comum que eles contenham vírus ou busquem informações confidenciais do usuário. Sendo assim, o melhor modelo seria aquele que classifique corretamente spams o máximo possível, mesmo que para isso ele sugira que mensagens normais sejam spams também.\n",
        "\n",
        "Neste caso, a melhor métrica para avaliar seria Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "xg1kliP2pUqP",
        "outputId": "f46a96be-b15b-4941-ab16-8a5f3f3080cd"
      },
      "source": [
        "d_2 = { \" \": ['Acurácia', 'Precisão', 'Recall', 'F1 score'],\n",
        "    \"Modelo Bag of Words\": [accuracy_score(y_bag_test, predictions_bag),\n",
        "                            precision_score(y_bag_test, predictions_bag,pos_label='spam'),\n",
        "                            recall_score(y_bag_test, predictions_bag,pos_label='spam'),\n",
        "                            f1_score(y_bag_test, predictions_bag,pos_label='spam')],\n",
        "    \"Modelo Word2Vec\": [accuracy_score(y_w2v_test, predictions_w2v),\n",
        "                        precision_score(y_w2v_test, predictions_w2v,pos_label='spam'),\n",
        "                        recall_score(y_w2v_test, predictions_w2v,pos_label='spam'),\n",
        "                        f1_score(y_w2v_test, predictions_w2v,pos_label='spam')]\n",
        "}\n",
        "df_2 = pd.DataFrame(data = d_2)\n",
        "df_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Modelo Bag of Words</th>\n",
              "      <th>Modelo Word2Vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Acurácia</td>\n",
              "      <td>0.928273</td>\n",
              "      <td>0.956366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Precisão</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recall</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.897321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F1 score</td>\n",
              "      <td>0.634146</td>\n",
              "      <td>0.846316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Modelo Bag of Words  Modelo Word2Vec\n",
              "0  Acurácia             0.928273         0.956366\n",
              "1  Precisão             1.000000         0.800797\n",
              "2    Recall             0.464286         0.897321\n",
              "3  F1 score             0.634146         0.846316"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-buczflAPfl",
        "outputId": "766d240b-8479-4934-b849-1b86a8da4d62"
      },
      "source": [
        "confusion_matrix(y_bag_test,predictions_bag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1449,    0],\n",
              "       [ 120,  104]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-WicwX2AlPY",
        "outputId": "e33029a4-954e-4533-9c6f-e9b964508c1f"
      },
      "source": [
        "confusion_matrix(y_w2v_test,predictions_w2v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1399,   50],\n",
              "       [  23,  201]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gC4Bd8lr-cP"
      },
      "source": [
        "O modelo usando Bag of Words, apesar de ter uma boa acurácia, não foi um bom modelo para o nosso problema, devido ao seu baixo Recall.\n",
        "\n",
        "Fazendo uma comparação, o modelo Bag of Words teve 120 casos de falso negativo, enquanto o Word2Vec teve 23 casos, em um total de 1673 casos de teste. \n",
        "\n",
        "Considerando uma cidade com uma população de 100 mil habitantes que recebem um SMS por dia, teríamos 7173 pessoas recebendo Spam sem serem alertados no primeiro modelo, já no segundo teríamos 1375. \n",
        "\n",
        "Por fim, o vencedor seria o modelo Word2Vector.\n",
        "\n",
        "Este resultado consideou também o custo computacional. A base utilizada possui menos de 6000 SMS, porém, no \"mundo real\" teríamos um a base com uma quantidade muito superior de dados.\n",
        "\n",
        "Deixando de lado o custo computacional, utilizando o modelo BERT, tivemos resultados muito superiores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyIH_aEyC_6u",
        "outputId": "9abd4a7a-76f0-4720-f4c6-edc485a61fc7"
      },
      "source": [
        "resul"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1447\n",
            "           1       0.99      0.97      0.98       226\n",
            "\n",
            "    accuracy                           0.99      1673\n",
            "   macro avg       0.99      0.98      0.99      1673\n",
            "weighted avg       0.99      0.99      0.99      1673\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1445,    2],\n",
              "       [   7,  219]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt6sN8PxHmjI"
      },
      "source": [
        "Usando o exemplo anterior da cidade com 100 mil habitantes, com o BERT teríamos 418 recebendo Spam sem alerta, um valor 3 vezes menor que o Word2Vec e 17 vezes menor que o Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ6Fi-ztpef8"
      },
      "source": [
        "# Uso do conhecimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX2RpRuTEELb"
      },
      "source": [
        "Neste trabalho extraimos padrões de um conjunto de SMS, sendo assim, a aplicação mais óbvia é implementar o modelo no aplicativo de mensagens do usuário para que ele seja notificado caso aquele SMS tenha características de Spam, porém, isso também poderia ser feito com emails e caixas de mensagens em redes sociais como facebook e instagram."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2j7SvJ7hzQAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refazer: : Em relação ao pre-processamneto, poderia ter variado o max_features da BoW e utilizar o tfidf. Em relação a classificação, poderia ter variado alguns parâmetros do método (número de vizinhos no kNN) e utilizar outros métodos interessantes para classificação para compara-los. No mundo real, pode ser mais facil para o usuario identificar Spams no meio de mensagem\n",
        "reais que ele vai olhar com calma porque são importantes, em vez de procurar pro mensagens reais no meio de varias Spams (mensagens\n",
        "nao importantes)? Considerar a F1-Score invés do recall? "
      ],
      "metadata": {
        "id": "OeMm_Wadi2Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rgsHOLugjqcN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}