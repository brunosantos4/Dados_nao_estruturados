{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Aluno: Bruno Ricardo Pereira dos Santos Santos \n",
        "\n",
        "Nº USP: 10288640"
      ],
      "metadata": {
        "id": "hFotDtRiST4N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsH8XysvhZeS"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import IPython\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.utils import np_utils, to_categorical, plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIZR-h8ikUC",
        "outputId": "a57097a6-ffbd-4a00-83e2-052697388625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/karolpiczak/ESC-50"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESC-50'...\n",
            "remote: Enumerating objects: 4163, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 4163 (delta 16), reused 0 (delta 0), pack-reused 4136\u001b[K\n",
            "Receiving objects: 100% (4163/4163), 878.78 MiB | 11.88 MiB/s, done.\n",
            "Resolving deltas: 100% (263/263), done.\n",
            "Checking out files: 100% (2011/2011), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problema\n",
        "\n",
        "Peguei dados da base acima e selecionei duas classes,  breathing e snoring. Achei interessante essas duas classes pois há vários aplicativos de celular para monitoramento de sono que indicam se a pessoa ronca ou não e quero verificar se esses apps conseguem realmente classificar corretamente. Sendo assim, importei os dados, os transformei e extraí padrões usando modelos de machine learning e CNN."
      ],
      "metadata": {
        "id": "kxMC02pw4FV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtenção e processamento dos dados"
      ],
      "metadata": {
        "id": "k_DJ3AAT7BqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "legenda = pd.read_csv('ESC-50/meta/esc50.csv')\n",
        "\n",
        "legenda1 = legenda[legenda['category']=='breathing']\n",
        "legenda2 = legenda[legenda['category']=='snoring']\n",
        "\n",
        "b_wav_files = legenda1['filename']\n",
        "s_wav_files = legenda2['filename']\n",
        "\n",
        "legenda2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ygdhkQ6WVLZm",
        "outputId": "dc149f02-51c9-4df1-fd6b-e83fba02871b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             filename  fold  target category  esc10  src_file take\n",
              "97   1-20545-A-28.wav     1      28  snoring  False     20545    A\n",
              "144  1-27403-A-28.wav     1      28  snoring  False     27403    A\n",
              "145  1-27405-A-28.wav     1      28  snoring  False     27405    A\n",
              "198  1-39937-A-28.wav     1      28  snoring  False     39937    A\n",
              "200  1-40621-A-28.wav     1      28  snoring  False     40621    A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42aaecb2-3570-4cb5-a858-0300e1731cca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>fold</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "      <th>esc10</th>\n",
              "      <th>src_file</th>\n",
              "      <th>take</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1-20545-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>20545</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>1-27403-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>27403</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>1-27405-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>27405</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>1-39937-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>39937</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>1-40621-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>40621</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42aaecb2-3570-4cb5-a858-0300e1731cca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42aaecb2-3570-4cb5-a858-0300e1731cca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42aaecb2-3570-4cb5-a858-0300e1731cca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiQkTS5Ajdcg"
      },
      "source": [
        "#from os import listdir\n",
        "#from os.path import isfile, join\n",
        "#b_wav_files = [f for f in listdir('ESC-50/audio/') if f == '1-52323-A-24.wav']\n",
        "#c_wav_files = [f for f in listdir('ESC-50/audio/') if f in legenda2['filename']]\n",
        "b_wav_files "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8aBmW5sk2Ui"
      },
      "source": [
        "import librosa\n",
        "\n",
        "def get_mel_spectrogram(file_path, max_padding=0, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    try:\n",
        "        # Load audio file\n",
        "        y, sr = librosa.load(file_path)\n",
        "\n",
        "        # Normalize audio data between -1 and 1\n",
        "        normalized_y = librosa.util.normalize(y)\n",
        "\n",
        "        # Generate mel scaled filterbanks\n",
        "        mel = librosa.feature.melspectrogram(normalized_y, sr=sr, n_mels=n_mels)\n",
        "\n",
        "        # Convert sound intensity to log amplitude:\n",
        "        mel_db = librosa.amplitude_to_db(abs(mel))\n",
        "\n",
        "        # Normalize between -1 and 1\n",
        "        normalized_mel = librosa.util.normalize(mel_db)\n",
        "\n",
        "        # Should we require padding\n",
        "        shape = normalized_mel.shape[1]\n",
        "        if (max_padding > 0 & shape < max_padding):\n",
        "            xDiff = max_padding - shape\n",
        "            xLeft = xDiff//2\n",
        "            xRight = xDiff-xLeft\n",
        "            normalized_mel = np.pad(normalized_mel, pad_width=((0,0), (xLeft, xRight)), mode='constant')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing wavefile: \", e)\n",
        "        return None \n",
        "    return normalized_mel"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rixVZuqBht1i"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "frames_max = 0\n",
        "counter = 0\n",
        "total_samples = len(b_wav_files)+len(s_wav_files)\n",
        "n_mels=40\n",
        "\n",
        "\n",
        "for b_wav_file in b_wav_files:\n",
        "    file_path = 'ESC-50/audio/'+b_wav_file\n",
        "    class_label = 'breathing'\n",
        "\n",
        "    # Extract Log-Mel Spectrograms (do not add padding)\n",
        "    print(file_path)\n",
        "    mels = get_mel_spectrogram(file_path, 0, n_mels=n_mels)\n",
        "    \n",
        "    # Save current frame count\n",
        "    num_frames = mels.shape[1]\n",
        "    \n",
        "    # Add row (feature / label)\n",
        "    features.append(mels)\n",
        "    labels.append(class_label)\n",
        "\n",
        "    # Update frames maximum\n",
        "    if (num_frames > frames_max):\n",
        "        frames_max = num_frames\n",
        "\n",
        "for s_wav_file in s_wav_files:\n",
        "    file_path = 'ESC-50/audio/'+s_wav_file\n",
        "    class_label = 'snoring'\n",
        "\n",
        "    # Extract Log-Mel Spectrograms (do not add padding)\n",
        "    print(file_path)\n",
        "    mels = get_mel_spectrogram(file_path, 0, n_mels=n_mels)\n",
        "    \n",
        "    # Save current frame count\n",
        "    num_frames = mels.shape[1]\n",
        "    \n",
        "    # Add row (feature / label)\n",
        "    features.append(mels)\n",
        "    labels.append(class_label)\n",
        "\n",
        "    # Update frames maximum\n",
        "    if (num_frames > frames_max):\n",
        "        frames_max = num_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHSAUXt9ZQnO",
        "outputId": "8bae0ab5-d7dd-4fba-cb10-ff409955d4cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "melspec = get_mel_spectrogram('ESC-50/audio/5-251489-A-24.wav')\n",
        "melspec.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmvpRGzxZdo7",
        "outputId": "b61c2b02-0d69-4df8-a2d7-4e0f72963c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "melspec = get_mel_spectrogram('ESC-50/audio/5-251489-A-24.wav')\n",
        "melspec.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEXXdJJ3kfuE"
      },
      "source": [
        "# Given an numpy array of features, zero-pads each ocurrence to max_padding\n",
        "def add_padding(features, max_padding=174):\n",
        "    padded = []\n",
        "\n",
        "    # Add padding\n",
        "    for i in range(len(features)):\n",
        "        px = features[i]\n",
        "        size = len(px[0])\n",
        "        # Add padding if required\n",
        "        if (size < max_padding):\n",
        "            xDiff = max_padding - size\n",
        "            xLeft = xDiff//2\n",
        "            xRight = xDiff-xLeft\n",
        "            px = np.pad(px, pad_width=((0,0), (xLeft, xRight)), mode='constant')\n",
        "        \n",
        "        padded.append(px)\n",
        "\n",
        "    return padded"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0-EKTYYlnNN"
      },
      "source": [
        "padded_features = add_padding(features, frames_max)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iSn0NgClscv"
      },
      "source": [
        "X = np.array(padded_features)\n",
        "y = np.array(labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S7NgvoOaIMf",
        "outputId": "3b151553-b0e5-4ee9-8f9e-d8dbdc4a7714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 40, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVC e MLP classifier"
      ],
      "metadata": {
        "id": "5djqeBd26G5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ = X.reshape(80,8640)\n"
      ],
      "metadata": {
        "id": "U0v44lNn1i4_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_,y,test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "CkmvPAl_33XF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "clf = SVC(random_state=42).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "predictions_2 = list(clf.predict(X_test))\n",
        "\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions_2)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predictions_2,pos_label='breathing')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_2,pos_label='breathing')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_2,pos_label='breathing')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhWrWvZa6V41",
        "outputId": "2f29a664-54ee-4d8e-9aae-d237b1188ae1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.85\n",
            "Precision score: 1.0\n",
            "Recall score: 0.7272727272727273\n",
            "F1 score: 0.8421052631578948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Precision score: {}'.format(precision_score(y_test, predictions_2,pos_label='snoring')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_2,pos_label='snoring')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_2,pos_label='snoring')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZUUkQMW_aX6",
        "outputId": "7e459114-6a02-400b-e314-e2ff48d264b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision score: 0.75\n",
            "Recall score: 1.0\n",
            "F1 score: 0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ra1 = classification_report(y_test, predictions_2, labels=['snoring','breathing'], target_names=['snoring','breathing'])\n",
        "\n",
        "print(ra1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk8igcRyAgBu",
        "outputId": "b999544f-ae93-4eb8-8a22-1070128630e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.75      1.00      0.86         9\n",
            "   breathing       1.00      0.73      0.84        11\n",
            "\n",
            "    accuracy                           0.85        20\n",
            "   macro avg       0.88      0.86      0.85        20\n",
            "weighted avg       0.89      0.85      0.85        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(random_state=42, max_iter=300).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "predictions_1 = list(clf.predict(X_test))\n",
        "\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions_1)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predictions_1,pos_label='breathing')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_1,pos_label='breathing')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_1,pos_label='breathing')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Uq_Ugc6WFL",
        "outputId": "3860413c-6c84-41e7-8083-83babfe2d26a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.55\n",
            "Precision score: 0.5714285714285714\n",
            "Recall score: 0.7272727272727273\n",
            "F1 score: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdC7NCGQaHO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb1b7d6-d19c-41b7-bf71-dfda212efe77"
      },
      "source": [
        "print('Precision score: {}'.format(precision_score(y_test, predictions_1,pos_label='snoring')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_1,pos_label='snoring')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_1,pos_label='snoring')))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision score: 0.5\n",
            "Recall score: 0.3333333333333333\n",
            "F1 score: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ra2 = classification_report(y_test, predictions_1, labels=['snoring','breathing'], target_names=['snoring','breathing'])\n",
        "\n",
        "print(ra2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFPufOySAlgu",
        "outputId": "7c012b83-5c54-4f04-e4a3-ebc4a18a362b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.50      0.33      0.40         9\n",
            "   breathing       0.57      0.73      0.64        11\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.54      0.53      0.52        20\n",
            "weighted avg       0.54      0.55      0.53        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "NkLMfE4J6r-S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWgSBbFel0Gt"
      },
      "source": [
        "np.save(\"X-mel_spec\", X)\n",
        "np.save(\"y-mel_spec\", y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibcX4j0rmJjG",
        "outputId": "4eafad3d-392c-4063-b222-ac6ec189765f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "indexes = []\n",
        "total = total_samples\n",
        "indexes = list(range(0, total))\n",
        "\n",
        "# Randomize indexes\n",
        "random.shuffle(indexes)\n",
        "\n",
        "# Divide the indexes into Train and Test\n",
        "test_split_pct = 25                        # 30 dados de treino 10 de teste\n",
        "split_offset = math.floor(test_split_pct * total / 100)\n",
        "\n",
        "# Split the metadata\n",
        "test_split_idx = indexes[0:split_offset]\n",
        "train_split_idx = indexes[split_offset:total]\n",
        "\n",
        "\n",
        "# Split the features with the same indexes\n",
        "X_test = np.take(X, test_split_idx, axis=0)\n",
        "y_test = np.take(y, test_split_idx, axis=0)\n",
        "X_train = np.take(X, train_split_idx, axis=0)\n",
        "y_train = np.take(y, train_split_idx, axis=0)\n",
        "\n",
        "# Print status\n",
        "print(\"X test shape: {} \\t X train shape: {}\".format(X_test.shape, X_train.shape))\n",
        "print(\"y test shape: {} \\t\\t y train shape: {}\".format(y_test.shape, y_train.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X test shape: (20, 40, 216) \t X train shape: (60, 40, 216)\n",
            "y test shape: (20,) \t\t y train shape: (60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNmk78GmrHw"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "le = LabelEncoder()\n",
        "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
        "y_train_encoded = to_categorical(le.fit_transform(y_train))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzTVpoypaubK",
        "outputId": "42dd096f-f7b8-4555-d6bd-7f23bcb35eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test_encoded"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjghJGKm25m"
      },
      "source": [
        "# How data should be structured\n",
        "num_rows = 40\n",
        "num_columns = 216\n",
        "num_channels = 1\n",
        "\n",
        "# Reshape to fit the network input (channel last)\n",
        "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
        "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
        "\n",
        "# Total number of labels to predict (equal to the network output nodes)\n",
        "num_labels = y_train_encoded.shape[1]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhBtT6V2m8s3",
        "outputId": "e8a7b283-0c60-4dd9-dab9-997be49f3e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 40, 216, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-8t33v_nV5F"
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    # Create a secquential object\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    # Conv 1\n",
        "    model.add(Conv2D(filters=32, \n",
        "                     kernel_size=(3, 3), \n",
        "                     input_shape=(num_rows, num_columns, num_channels)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=32, \n",
        "                     kernel_size=(3, 3)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # Max Pooling #1\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, \n",
        "                     kernel_size=(3, 3)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=64, \n",
        "                     kernel_size=(3,3)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "   \n",
        "    # Reduces each h×w feature map to a single number by taking the average of all h,w values.\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "\n",
        "    # Softmax output\n",
        "    model.add(Dense(num_labels, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcjBMi9uneKM",
        "outputId": "fe393b88-6a1a-427a-b1b7-37f96a36e678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',  # duas classes\n",
        "    metrics=['accuracy'],  \n",
        "    optimizer='adam')\n",
        "\n",
        "# Display model architecture summary \n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 38, 214, 32)       320       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 38, 214, 32)       0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 38, 214, 32)      128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 36, 212, 32)       9248      \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 36, 212, 32)       0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 36, 212, 32)      128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 18, 106, 32)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 104, 64)       18496     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 16, 104, 64)       0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 104, 64)      256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 102, 64)       36928     \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 102, 64)       0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 14, 102, 64)      256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 64)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,890\n",
            "Trainable params: 65,506\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjCKJgWlnh_p",
        "outputId": "acc90c70-3df1-4d46-c95a-692507ee142b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(X_train, \n",
        "                    y_train_encoded, \n",
        "                    batch_size=4, \n",
        "                    epochs=50, \n",
        "                    validation_data=(X_test,y_test_encoded),\n",
        "                    verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 11s 32ms/step - loss: 0.5689 - accuracy: 0.7000 - val_loss: 0.6655 - val_accuracy: 0.6000\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.4389 - accuracy: 0.8167 - val_loss: 0.6859 - val_accuracy: 0.6000\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.4431 - accuracy: 0.8500 - val_loss: 0.6951 - val_accuracy: 0.6000\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.5123 - accuracy: 0.7667 - val_loss: 0.6916 - val_accuracy: 0.6000\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.4572 - accuracy: 0.7667 - val_loss: 0.7333 - val_accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3883 - accuracy: 0.8167 - val_loss: 0.6936 - val_accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3594 - accuracy: 0.8500 - val_loss: 0.6938 - val_accuracy: 0.6000\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.9000 - val_loss: 0.7067 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3519 - accuracy: 0.8833 - val_loss: 0.7070 - val_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.4118 - accuracy: 0.8167 - val_loss: 0.7468 - val_accuracy: 0.2500\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3911 - accuracy: 0.8167 - val_loss: 0.7068 - val_accuracy: 0.5500\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.4085 - accuracy: 0.8167 - val_loss: 0.6767 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3138 - accuracy: 0.9167 - val_loss: 1.0212 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3386 - accuracy: 0.8500 - val_loss: 0.9032 - val_accuracy: 0.1500\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3915 - accuracy: 0.8833 - val_loss: 0.9389 - val_accuracy: 0.3000\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3812 - accuracy: 0.8500 - val_loss: 0.8964 - val_accuracy: 0.3500\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.8667 - val_loss: 0.8815 - val_accuracy: 0.3000\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.4201 - accuracy: 0.8500 - val_loss: 0.8398 - val_accuracy: 0.4000\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.4524 - accuracy: 0.7833 - val_loss: 0.8727 - val_accuracy: 0.3000\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3518 - accuracy: 0.8833 - val_loss: 0.7995 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3981 - accuracy: 0.7833 - val_loss: 0.8154 - val_accuracy: 0.3000\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3309 - accuracy: 0.9167 - val_loss: 0.6766 - val_accuracy: 0.6500\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3995 - accuracy: 0.8167 - val_loss: 0.7236 - val_accuracy: 0.4500\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3250 - accuracy: 0.8833 - val_loss: 0.7968 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.4402 - accuracy: 0.7667 - val_loss: 0.6309 - val_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2748 - accuracy: 0.8333 - val_loss: 0.5579 - val_accuracy: 0.9000\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3478 - accuracy: 0.8333 - val_loss: 0.7327 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2466 - accuracy: 0.9500 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2279 - accuracy: 0.9000 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3511 - accuracy: 0.8333 - val_loss: 0.6307 - val_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2883 - accuracy: 0.8833 - val_loss: 0.9237 - val_accuracy: 0.4500\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2414 - accuracy: 0.9167 - val_loss: 0.6462 - val_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2770 - accuracy: 0.8833 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3788 - accuracy: 0.8167 - val_loss: 1.0286 - val_accuracy: 0.4000\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.4079 - accuracy: 0.8500 - val_loss: 0.4310 - val_accuracy: 0.8500\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2194 - accuracy: 0.9333 - val_loss: 0.4640 - val_accuracy: 0.8500\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2833 - accuracy: 0.9000 - val_loss: 0.4104 - val_accuracy: 0.9000\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.4046 - accuracy: 0.8500 - val_loss: 0.5809 - val_accuracy: 0.6500\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2334 - accuracy: 0.9333 - val_loss: 0.3602 - val_accuracy: 0.8500\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2738 - accuracy: 0.8667 - val_loss: 0.3311 - val_accuracy: 0.9000\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.1580 - accuracy: 0.9333 - val_loss: 0.3944 - val_accuracy: 0.8000\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2147 - accuracy: 0.9000 - val_loss: 0.4388 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2113 - accuracy: 0.9500 - val_loss: 0.3064 - val_accuracy: 0.9000\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2354 - accuracy: 0.9333 - val_loss: 0.3252 - val_accuracy: 0.8000\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3129 - accuracy: 0.8833 - val_loss: 0.9540 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2079 - accuracy: 0.9333 - val_loss: 1.5911 - val_accuracy: 0.6500\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2706 - accuracy: 0.9333 - val_loss: 0.4542 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3922 - accuracy: 0.8333 - val_loss: 0.8990 - val_accuracy: 0.6500\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2101 - accuracy: 0.9167 - val_loss: 0.3150 - val_accuracy: 0.9000\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.3168 - accuracy: 0.8500 - val_loss: 0.7596 - val_accuracy: 0.5500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzPLrMBpnthJ",
        "outputId": "2569916e-4067-48c2-b095-359866630fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Plots a confussion matrix\n",
        "def plot_confusion_matrix(cm,\n",
        "                          classes, \n",
        "                          normalized=False, \n",
        "                          title=None, \n",
        "                          cmap=plt.cm.Blues,\n",
        "                          size=(10,10)):\n",
        "    fig, ax = plt.subplots(figsize=size)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalized else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "y_probs = model.predict(X_test, verbose=0)\n",
        "\n",
        "# Get predicted labels\n",
        "yhat_probs = np.argmax(y_probs, axis=1)\n",
        "y_trues = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "\n",
        "# Sets decimal precision (for printing output only)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Compute confusion matrix data\n",
        "cm = confusion_matrix(y_trues, yhat_probs)\n",
        "\n",
        "\n",
        "\n",
        "plot_confusion_matrix(cm,\n",
        "                          ['snoring','breathing'], \n",
        "                          normalized=False, \n",
        "                          title=\"Model Performance\", \n",
        "                          cmap=plt.cm.Blues,\n",
        "                          size=(4,4))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK0LVaVaqufg",
        "outputId": "0af49d1b-8338-4a59-d2ba-8a477acbaf83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "re = classification_report(y_trues, yhat_probs, labels=[0,1], target_names=['snoring','breathing'])\n",
        "\n",
        "print(re)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.45      0.62      0.53         8\n",
            "   breathing       0.67      0.50      0.57        12\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.56      0.56      0.55        20\n",
            "weighted avg       0.58      0.55      0.55        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando CNN com SVC (o melhor modelo da etapa anterior):"
      ],
      "metadata": {
        "id": "Zoi17S2GAFAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ra1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i752j65AJeS",
        "outputId": "a3248df8-bf62-48e2-fc6b-004ab6d4b349"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.75      1.00      0.86         9\n",
            "   breathing       1.00      0.73      0.84        11\n",
            "\n",
            "    accuracy                           0.85        20\n",
            "   macro avg       0.88      0.86      0.85        20\n",
            "weighted avg       0.89      0.85      0.85        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De modo geral o SVC obteve melhor desempenho que o CNN, mas ainda assim o resultado poderia ser muito melhor caso tivéssemos uma base maior e assim mais dados para treino."
      ],
      "metadata": {
        "id": "jNk20prL_mly"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQeO5p7bcL6M"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coisas para refazer:  \n",
        "\n",
        "(Conjuntos de teste e treino deveriam ser os mesmos na CNN e no SVM e MLP. No SVM e MLP utilizei o train_test_split e na CNN fiz uma separação diferente.) Utilizar a separação feita na CNN, realizar o reshape e aplicar o SVM e MLP."
      ],
      "metadata": {
        "id": "QtWJpRsHfQDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1HevXPk1fVW0"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}