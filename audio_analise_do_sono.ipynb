{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Aluno: Bruno Ricardo Pereira dos Santos Santos \n",
        "\n",
        "Nº USP: 10288640"
      ],
      "metadata": {
        "id": "hFotDtRiST4N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsH8XysvhZeS"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import IPython\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, LeakyReLU, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.utils import np_utils, to_categorical, plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIZR-h8ikUC",
        "outputId": "ca002e73-7b31-4512-8198-b139e2226cb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/karolpiczak/ESC-50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESC-50'...\n",
            "remote: Enumerating objects: 4157, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 4157 (delta 12), reused 0 (delta 0), pack-reused 4136\u001b[K\n",
            "Receiving objects: 100% (4157/4157), 878.78 MiB | 21.46 MiB/s, done.\n",
            "Resolving deltas: 100% (259/259), done.\n",
            "Checking out files: 100% (2011/2011), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problema\n",
        "\n",
        "Peguei dados da base acima e selecionei duas classes,  breathing e snoring. Achei interessante essas duas classes pois há vários aplicativos de celular para monitoramento de sono que indicam se a pessoa ronca ou não e quero verificar se esses apps conseguem realmente classificar corretamente. Sendo assim, importei os dados, os transformei e extraí padrões usando modelos de machine learning e CNN."
      ],
      "metadata": {
        "id": "kxMC02pw4FV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtenção e processamento dos dados"
      ],
      "metadata": {
        "id": "k_DJ3AAT7BqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "legenda = pd.read_csv('ESC-50/meta/esc50.csv')\n",
        "\n",
        "legenda1 = legenda[legenda['category']=='breathing']\n",
        "legenda2 = legenda[legenda['category']=='snoring']\n",
        "\n",
        "b_wav_files = legenda1['filename']\n",
        "s_wav_files = legenda2['filename']\n",
        "\n",
        "legenda2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ygdhkQ6WVLZm",
        "outputId": "bdeaa848-9d2e-4992-b10c-4bede77edb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a23c31d-08e3-452e-9f9f-a44070644154\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>fold</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "      <th>esc10</th>\n",
              "      <th>src_file</th>\n",
              "      <th>take</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1-20545-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>20545</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>1-27403-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>27403</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>1-27405-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>27405</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>1-39937-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>39937</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>1-40621-A-28.wav</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>snoring</td>\n",
              "      <td>False</td>\n",
              "      <td>40621</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a23c31d-08e3-452e-9f9f-a44070644154')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a23c31d-08e3-452e-9f9f-a44070644154 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a23c31d-08e3-452e-9f9f-a44070644154');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             filename  fold  target category  esc10  src_file take\n",
              "97   1-20545-A-28.wav     1      28  snoring  False     20545    A\n",
              "144  1-27403-A-28.wav     1      28  snoring  False     27403    A\n",
              "145  1-27405-A-28.wav     1      28  snoring  False     27405    A\n",
              "198  1-39937-A-28.wav     1      28  snoring  False     39937    A\n",
              "200  1-40621-A-28.wav     1      28  snoring  False     40621    A"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiQkTS5Ajdcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38573310-4734-4333-a33d-e45fe7ae8534"
      },
      "source": [
        "#from os import listdir\n",
        "#from os.path import isfile, join\n",
        "#b_wav_files = [f for f in listdir('ESC-50/audio/') if f == '1-52323-A-24.wav']\n",
        "#c_wav_files = [f for f in listdir('ESC-50/audio/') if f in legenda2['filename']]\n",
        "b_wav_files "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76       1-18631-A-23.wav\n",
              "159      1-30709-A-23.wav\n",
              "160      1-30709-B-23.wav\n",
              "161      1-30709-C-23.wav\n",
              "185      1-36393-A-23.wav\n",
              "186      1-36397-A-23.wav\n",
              "187      1-36400-A-23.wav\n",
              "188      1-36402-A-23.wav\n",
              "649      2-50774-A-23.wav\n",
              "659      2-54961-A-23.wav\n",
              "660      2-54962-A-23.wav\n",
              "683      2-66205-A-23.wav\n",
              "750      2-82455-A-23.wav\n",
              "760      2-84965-A-23.wav\n",
              "786      2-95567-A-23.wav\n",
              "792      2-98392-A-23.wav\n",
              "829     3-108160-A-23.wav\n",
              "844     3-112557-A-23.wav\n",
              "845     3-112557-B-23.wav\n",
              "957     3-144128-A-23.wav\n",
              "958     3-144128-B-23.wav\n",
              "999     3-151206-A-23.wav\n",
              "1087    3-166125-A-23.wav\n",
              "1088    3-166125-B-23.wav\n",
              "1360    4-171706-A-23.wav\n",
              "1392    4-176914-A-23.wav\n",
              "1507    4-198025-A-23.wav\n",
              "1536    4-205526-A-23.wav\n",
              "1537    4-205526-B-23.wav\n",
              "1539    4-207116-A-23.wav\n",
              "1544    4-210000-A-23.wav\n",
              "1545    4-210000-B-23.wav\n",
              "1805    5-213293-A-23.wav\n",
              "1874    5-232816-A-23.wav\n",
              "1877    5-233260-A-23.wav\n",
              "1886    5-234335-A-23.wav\n",
              "1892    5-235593-A-23.wav\n",
              "1904    5-238492-A-23.wav\n",
              "1978    5-260164-A-23.wav\n",
              "1986    5-261464-A-23.wav\n",
              "Name: filename, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8aBmW5sk2Ui"
      },
      "source": [
        "import librosa\n",
        "\n",
        "def get_mel_spectrogram(file_path, max_padding=0, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    try:\n",
        "        # Load audio file\n",
        "        y, sr = librosa.load(file_path)\n",
        "\n",
        "        # Normalize audio data between -1 and 1\n",
        "        normalized_y = librosa.util.normalize(y)\n",
        "\n",
        "        # Generate mel scaled filterbanks\n",
        "        mel = librosa.feature.melspectrogram(normalized_y, sr=sr, n_mels=n_mels)\n",
        "\n",
        "        # Convert sound intensity to log amplitude:\n",
        "        mel_db = librosa.amplitude_to_db(abs(mel))\n",
        "\n",
        "        # Normalize between -1 and 1\n",
        "        normalized_mel = librosa.util.normalize(mel_db)\n",
        "\n",
        "        # Should we require padding\n",
        "        shape = normalized_mel.shape[1]\n",
        "        if (max_padding > 0 & shape < max_padding):\n",
        "            xDiff = max_padding - shape\n",
        "            xLeft = xDiff//2\n",
        "            xRight = xDiff-xLeft\n",
        "            normalized_mel = np.pad(normalized_mel, pad_width=((0,0), (xLeft, xRight)), mode='constant')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing wavefile: \", e)\n",
        "        return None \n",
        "    return normalized_mel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rixVZuqBht1i",
        "outputId": "5b83ab8e-746d-4395-a419-c0c05637f255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "frames_max = 0\n",
        "counter = 0\n",
        "total_samples = len(b_wav_files)+len(s_wav_files)\n",
        "n_mels=40\n",
        "\n",
        "\n",
        "for b_wav_file in b_wav_files:\n",
        "    file_path = 'ESC-50/audio/'+b_wav_file\n",
        "    class_label = 'breathing'\n",
        "\n",
        "    # Extract Log-Mel Spectrograms (do not add padding)\n",
        "    print(file_path)\n",
        "    mels = get_mel_spectrogram(file_path, 0, n_mels=n_mels)\n",
        "    \n",
        "    # Save current frame count\n",
        "    num_frames = mels.shape[1]\n",
        "    \n",
        "    # Add row (feature / label)\n",
        "    features.append(mels)\n",
        "    labels.append(class_label)\n",
        "\n",
        "    # Update frames maximum\n",
        "    if (num_frames > frames_max):\n",
        "        frames_max = num_frames\n",
        "\n",
        "for s_wav_file in s_wav_files:\n",
        "    file_path = 'ESC-50/audio/'+s_wav_file\n",
        "    class_label = 'snoring'\n",
        "\n",
        "    # Extract Log-Mel Spectrograms (do not add padding)\n",
        "    print(file_path)\n",
        "    mels = get_mel_spectrogram(file_path, 0, n_mels=n_mels)\n",
        "    \n",
        "    # Save current frame count\n",
        "    num_frames = mels.shape[1]\n",
        "    \n",
        "    # Add row (feature / label)\n",
        "    features.append(mels)\n",
        "    labels.append(class_label)\n",
        "\n",
        "    # Update frames maximum\n",
        "    if (num_frames > frames_max):\n",
        "        frames_max = num_frames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESC-50/audio/1-18631-A-23.wav\n",
            "ESC-50/audio/1-30709-A-23.wav\n",
            "ESC-50/audio/1-30709-B-23.wav\n",
            "ESC-50/audio/1-30709-C-23.wav\n",
            "ESC-50/audio/1-36393-A-23.wav\n",
            "ESC-50/audio/1-36397-A-23.wav\n",
            "ESC-50/audio/1-36400-A-23.wav\n",
            "ESC-50/audio/1-36402-A-23.wav\n",
            "ESC-50/audio/2-50774-A-23.wav\n",
            "ESC-50/audio/2-54961-A-23.wav\n",
            "ESC-50/audio/2-54962-A-23.wav\n",
            "ESC-50/audio/2-66205-A-23.wav\n",
            "ESC-50/audio/2-82455-A-23.wav\n",
            "ESC-50/audio/2-84965-A-23.wav\n",
            "ESC-50/audio/2-95567-A-23.wav\n",
            "ESC-50/audio/2-98392-A-23.wav\n",
            "ESC-50/audio/3-108160-A-23.wav\n",
            "ESC-50/audio/3-112557-A-23.wav\n",
            "ESC-50/audio/3-112557-B-23.wav\n",
            "ESC-50/audio/3-144128-A-23.wav\n",
            "ESC-50/audio/3-144128-B-23.wav\n",
            "ESC-50/audio/3-151206-A-23.wav\n",
            "ESC-50/audio/3-166125-A-23.wav\n",
            "ESC-50/audio/3-166125-B-23.wav\n",
            "ESC-50/audio/4-171706-A-23.wav\n",
            "ESC-50/audio/4-176914-A-23.wav\n",
            "ESC-50/audio/4-198025-A-23.wav\n",
            "ESC-50/audio/4-205526-A-23.wav\n",
            "ESC-50/audio/4-205526-B-23.wav\n",
            "ESC-50/audio/4-207116-A-23.wav\n",
            "ESC-50/audio/4-210000-A-23.wav\n",
            "ESC-50/audio/4-210000-B-23.wav\n",
            "ESC-50/audio/5-213293-A-23.wav\n",
            "ESC-50/audio/5-232816-A-23.wav\n",
            "ESC-50/audio/5-233260-A-23.wav\n",
            "ESC-50/audio/5-234335-A-23.wav\n",
            "ESC-50/audio/5-235593-A-23.wav\n",
            "ESC-50/audio/5-238492-A-23.wav\n",
            "ESC-50/audio/5-260164-A-23.wav\n",
            "ESC-50/audio/5-261464-A-23.wav\n",
            "ESC-50/audio/1-20545-A-28.wav\n",
            "ESC-50/audio/1-27403-A-28.wav\n",
            "ESC-50/audio/1-27405-A-28.wav\n",
            "ESC-50/audio/1-39937-A-28.wav\n",
            "ESC-50/audio/1-40621-A-28.wav\n",
            "ESC-50/audio/1-40967-A-28.wav\n",
            "ESC-50/audio/1-47923-A-28.wav\n",
            "ESC-50/audio/1-53444-A-28.wav\n",
            "ESC-50/audio/2-110417-A-28.wav\n",
            "ESC-50/audio/2-110417-B-28.wav\n",
            "ESC-50/audio/2-114609-A-28.wav\n",
            "ESC-50/audio/2-114609-B-28.wav\n",
            "ESC-50/audio/2-117330-A-28.wav\n",
            "ESC-50/audio/2-52001-A-28.wav\n",
            "ESC-50/audio/2-52001-B-28.wav\n",
            "ESC-50/audio/2-80313-A-28.wav\n",
            "ESC-50/audio/3-123086-A-28.wav\n",
            "ESC-50/audio/3-124795-A-28.wav\n",
            "ESC-50/audio/3-124958-A-28.wav\n",
            "ESC-50/audio/3-130998-A-28.wav\n",
            "ESC-50/audio/3-130998-B-28.wav\n",
            "ESC-50/audio/3-151255-A-28.wav\n",
            "ESC-50/audio/3-151557-A-28.wav\n",
            "ESC-50/audio/3-151557-B-28.wav\n",
            "ESC-50/audio/4-180337-A-28.wav\n",
            "ESC-50/audio/4-183882-A-28.wav\n",
            "ESC-50/audio/4-183882-B-28.wav\n",
            "ESC-50/audio/4-184235-A-28.wav\n",
            "ESC-50/audio/4-184237-A-28.wav\n",
            "ESC-50/audio/4-191297-A-28.wav\n",
            "ESC-50/audio/4-197454-A-28.wav\n",
            "ESC-50/audio/4-197454-B-28.wav\n",
            "ESC-50/audio/5-216368-A-28.wav\n",
            "ESC-50/audio/5-233312-A-28.wav\n",
            "ESC-50/audio/5-234145-A-28.wav\n",
            "ESC-50/audio/5-235874-A-28.wav\n",
            "ESC-50/audio/5-235893-A-28.wav\n",
            "ESC-50/audio/5-236288-A-28.wav\n",
            "ESC-50/audio/5-244459-A-28.wav\n",
            "ESC-50/audio/5-249748-A-28.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHSAUXt9ZQnO",
        "outputId": "6502f1c1-dfe0-4063-e82e-a24fabdd5195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "melspec = get_mel_spectrogram('ESC-50/audio/5-251489-A-24.wav')\n",
        "melspec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmvpRGzxZdo7",
        "outputId": "e99ac317-7ce2-4ac2-f22d-8a748392967e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "melspec = get_mel_spectrogram('ESC-50/audio/5-251489-A-24.wav')\n",
        "melspec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEXXdJJ3kfuE"
      },
      "source": [
        "# Given an numpy array of features, zero-pads each ocurrence to max_padding\n",
        "def add_padding(features, max_padding=174):\n",
        "    padded = []\n",
        "\n",
        "    # Add padding\n",
        "    for i in range(len(features)):\n",
        "        px = features[i]\n",
        "        size = len(px[0])\n",
        "        # Add padding if required\n",
        "        if (size < max_padding):\n",
        "            xDiff = max_padding - size\n",
        "            xLeft = xDiff//2\n",
        "            xRight = xDiff-xLeft\n",
        "            px = np.pad(px, pad_width=((0,0), (xLeft, xRight)), mode='constant')\n",
        "        \n",
        "        padded.append(px)\n",
        "\n",
        "    return padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0-EKTYYlnNN"
      },
      "source": [
        "padded_features = add_padding(features, frames_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iSn0NgClscv"
      },
      "source": [
        "X = np.array(padded_features)\n",
        "y = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S7NgvoOaIMf",
        "outputId": "05fbde4b-c6e3-4b0f-82c7-ee0c0ff7fa12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 40, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OH3-IGZajg3",
        "outputId": "64b8f662-f5a7-4d5f-984f-097df1843ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 3.97e-01,  6.97e-01,  7.92e-01, ..., -4.84e-01, -9.37e-02,\n",
              "         -2.88e-01],\n",
              "        [ 8.09e-01,  9.18e-01,  8.89e-01, ..., -3.49e-03,  2.11e-01,\n",
              "          2.89e-01],\n",
              "        [ 1.00e+00,  9.62e-01,  5.11e-01, ..., -7.99e-02, -3.96e-02,\n",
              "          3.33e-01],\n",
              "        ...,\n",
              "        [-9.01e-01, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-9.01e-01, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-9.01e-01, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00]],\n",
              "\n",
              "       [[-9.32e-03,  3.44e-04, -1.42e-01, ...,  1.25e-01,  2.05e-01,\n",
              "          1.00e-01],\n",
              "        [-2.64e-01, -1.05e-01, -7.40e-03, ..., -2.48e-01, -1.19e-02,\n",
              "          1.35e-01],\n",
              "        [-3.15e-01, -2.84e-01, -1.98e-01, ..., -2.19e-01, -9.50e-02,\n",
              "         -1.87e-01],\n",
              "        ...,\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00]],\n",
              "\n",
              "       [[-3.76e-01, -1.93e-01, -6.51e-02, ...,  5.46e-01,  5.29e-01,\n",
              "          3.87e-01],\n",
              "        [-2.55e-01, -1.88e-01, -1.83e-01, ...,  5.23e-01,  5.47e-01,\n",
              "          5.59e-01],\n",
              "        [-1.57e-01, -1.33e-01, -1.63e-01, ...,  3.88e-01,  3.79e-01,\n",
              "          4.87e-01],\n",
              "        ...,\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -7.78e-01, -7.93e-01,\n",
              "         -7.77e-01],\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -7.78e-01, -7.93e-01,\n",
              "         -7.77e-01],\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -7.78e-01, -7.93e-01,\n",
              "         -7.77e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.00e+00,  1.00e+00,  1.00e+00, ...,  6.79e-01,  9.06e-01,\n",
              "          7.12e-01],\n",
              "        [ 4.85e-01,  4.95e-01,  5.33e-01, ..., -4.85e-01, -3.67e-01,\n",
              "         -5.12e-01],\n",
              "        [ 1.24e-01,  2.53e-01,  2.47e-01, ..., -6.22e-01, -5.47e-01,\n",
              "         -1.00e+00],\n",
              "        ...,\n",
              "        [-6.17e-01, -5.96e-01, -5.59e-01, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-6.17e-01, -5.96e-01, -5.59e-01, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-6.17e-01, -5.96e-01, -5.59e-01, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00]],\n",
              "\n",
              "       [[ 8.20e-01,  5.42e-01,  6.84e-01, ...,  7.88e-01,  6.55e-01,\n",
              "          7.00e-01],\n",
              "        [ 7.89e-01,  5.15e-01,  9.54e-03, ..., -3.67e-01, -4.92e-01,\n",
              "         -4.36e-01],\n",
              "        [ 2.45e-01, -1.76e-01, -5.24e-01, ..., -4.59e-01, -4.78e-01,\n",
              "         -6.23e-01],\n",
              "        ...,\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-1.00e+00, -1.00e+00, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00]],\n",
              "\n",
              "       [[ 7.04e-01,  7.07e-01,  4.45e-01, ..., -2.19e-01, -1.82e-01,\n",
              "         -2.39e-01],\n",
              "        [ 4.38e-01,  4.51e-01,  4.62e-01, ..., -1.00e+00, -8.73e-01,\n",
              "         -6.69e-01],\n",
              "        [ 2.15e-01,  1.78e-01,  1.43e-01, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        ...,\n",
              "        [-4.90e-01, -5.80e-01, -6.04e-01, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-8.52e-01, -9.95e-01, -1.00e+00, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00],\n",
              "        [-7.76e-01, -9.52e-01, -9.42e-01, ..., -1.00e+00, -1.00e+00,\n",
              "         -1.00e+00]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNPnYuqRlzYp",
        "outputId": "1b55f742-78f7-4e21-a779-7523d6971d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'breathing', 'breathing', 'breathing', 'breathing', 'breathing',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring', 'snoring', 'snoring',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring', 'snoring', 'snoring',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring', 'snoring', 'snoring',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring', 'snoring', 'snoring',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring', 'snoring', 'snoring',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring', 'snoring', 'snoring',\n",
              "       'snoring', 'snoring', 'snoring', 'snoring'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVC e MLP classifier"
      ],
      "metadata": {
        "id": "5djqeBd26G5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ = X.reshape(80,8640)\n"
      ],
      "metadata": {
        "id": "U0v44lNn1i4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_,y,test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "CkmvPAl_33XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "clf = SVC(random_state=42).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "predictions_2 = list(clf.predict(X_test))\n",
        "\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions_2)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predictions_2,pos_label='breathing')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_2,pos_label='breathing')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_2,pos_label='breathing')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhWrWvZa6V41",
        "outputId": "e04d24f9-a9eb-4f14-a3a7-8f84ec733973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.85\n",
            "Precision score: 1.0\n",
            "Recall score: 0.7272727272727273\n",
            "F1 score: 0.8421052631578948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Precision score: {}'.format(precision_score(y_test, predictions_2,pos_label='snoring')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_2,pos_label='snoring')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_2,pos_label='snoring')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZUUkQMW_aX6",
        "outputId": "08fdef4c-8480-4482-fb0d-c5da70123d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision score: 0.75\n",
            "Recall score: 1.0\n",
            "F1 score: 0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ra1 = classification_report(y_test, predictions_2, labels=['snoring','breathing'], target_names=['snoring','breathing'])\n",
        "\n",
        "print(ra1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk8igcRyAgBu",
        "outputId": "07ca9c72-5faf-4086-cd0e-c9ab11790a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.75      1.00      0.86         9\n",
            "   breathing       1.00      0.73      0.84        11\n",
            "\n",
            "    accuracy                           0.85        20\n",
            "   macro avg       0.88      0.86      0.85        20\n",
            "weighted avg       0.89      0.85      0.85        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(random_state=42, max_iter=300).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "predictions_1 = list(clf.predict(X_test))\n",
        "\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions_1)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predictions_1,pos_label='breathing')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_1,pos_label='breathing')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_1,pos_label='breathing')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Uq_Ugc6WFL",
        "outputId": "e7ac6bd9-fc40-4f1a-bc26-7370dc34c9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.55\n",
            "Precision score: 0.5714285714285714\n",
            "Recall score: 0.7272727272727273\n",
            "F1 score: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdC7NCGQaHO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f9995f-e2ce-45dd-f681-1694e0e74a1d"
      },
      "source": [
        "print('Precision score: {}'.format(precision_score(y_test, predictions_1,pos_label='snoring')))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predictions_1,pos_label='snoring')))\n",
        "print('F1 score: {}'.format(f1_score(y_test, predictions_1,pos_label='snoring')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision score: 0.5\n",
            "Recall score: 0.3333333333333333\n",
            "F1 score: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ra2 = classification_report(y_test, predictions_1, labels=['snoring','breathing'], target_names=['snoring','breathing'])\n",
        "\n",
        "print(ra2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFPufOySAlgu",
        "outputId": "362907c3-6cd9-43d9-d1f9-d698a79cec7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.50      0.33      0.40         9\n",
            "   breathing       0.57      0.73      0.64        11\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.54      0.53      0.52        20\n",
            "weighted avg       0.54      0.55      0.53        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "NkLMfE4J6r-S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWgSBbFel0Gt"
      },
      "source": [
        "np.save(\"X-mel_spec\", X)\n",
        "np.save(\"y-mel_spec\", y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibcX4j0rmJjG",
        "outputId": "d298c1f9-3d02-4d15-eaa8-47c55d44f15f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "indexes = []\n",
        "total = total_samples\n",
        "indexes = list(range(0, total))\n",
        "\n",
        "# Randomize indexes\n",
        "random.shuffle(indexes)\n",
        "\n",
        "# Divide the indexes into Train and Test\n",
        "test_split_pct = 25                        # 30 dados de treino 10 de teste\n",
        "split_offset = math.floor(test_split_pct * total / 100)\n",
        "\n",
        "# Split the metadata\n",
        "test_split_idx = indexes[0:split_offset]\n",
        "train_split_idx = indexes[split_offset:total]\n",
        "\n",
        "\n",
        "# Split the features with the same indexes\n",
        "X_test = np.take(X, test_split_idx, axis=0)\n",
        "y_test = np.take(y, test_split_idx, axis=0)\n",
        "X_train = np.take(X, train_split_idx, axis=0)\n",
        "y_train = np.take(y, train_split_idx, axis=0)\n",
        "\n",
        "# Print status\n",
        "print(\"X test shape: {} \\t X train shape: {}\".format(X_test.shape, X_train.shape))\n",
        "print(\"y test shape: {} \\t\\t y train shape: {}\".format(y_test.shape, y_train.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X test shape: (20, 40, 216) \t X train shape: (60, 40, 216)\n",
            "y test shape: (20,) \t\t y train shape: (60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNmk78GmrHw"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "le = LabelEncoder()\n",
        "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
        "y_train_encoded = to_categorical(le.fit_transform(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzTVpoypaubK",
        "outputId": "c8aa811c-310e-4703-d0cf-d4f831df4a23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test_encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjghJGKm25m"
      },
      "source": [
        "# How data should be structured\n",
        "num_rows = 40\n",
        "num_columns = 216\n",
        "num_channels = 1\n",
        "\n",
        "# Reshape to fit the network input (channel last)\n",
        "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
        "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
        "\n",
        "# Total number of labels to predict (equal to the network output nodes)\n",
        "num_labels = y_train_encoded.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhBtT6V2m8s3",
        "outputId": "61ef7451-3337-486f-b2dd-b3a3c39acf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 40, 216, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-8t33v_nV5F"
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    # Create a secquential object\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    # Conv 1\n",
        "    model.add(Conv2D(filters=32, \n",
        "                     kernel_size=(3, 3), \n",
        "                     input_shape=(num_rows, num_columns, num_channels)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=32, \n",
        "                     kernel_size=(3, 3)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # Max Pooling #1\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, \n",
        "                     kernel_size=(3, 3)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=64, \n",
        "                     kernel_size=(3,3)))\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "   \n",
        "    # Reduces each h×w feature map to a single number by taking the average of all h,w values.\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "\n",
        "    # Softmax output\n",
        "    model.add(Dense(num_labels, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcjBMi9uneKM",
        "outputId": "5ac6ea13-805a-4501-cb2f-11d50057a57d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',  # duas classes\n",
        "    metrics=['accuracy'],  \n",
        "    optimizer='adam')\n",
        "\n",
        "# Display model architecture summary \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 38, 214, 32)       320       \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 38, 214, 32)       0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 38, 214, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 36, 212, 32)       9248      \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 36, 212, 32)       0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 36, 212, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 18, 106, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 104, 64)       18496     \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 16, 104, 64)       0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 16, 104, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 14, 102, 64)       36928     \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 14, 102, 64)       0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 14, 102, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,890\n",
            "Trainable params: 65,506\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjCKJgWlnh_p",
        "outputId": "7069fed9-161b-4aab-a4e0-0770836162fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(X_train, \n",
        "                    y_train_encoded, \n",
        "                    batch_size=4, \n",
        "                    epochs=50, \n",
        "                    validation_data=(X_test,y_test_encoded),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 0.5808 - accuracy: 0.6833 - val_loss: 0.6729 - val_accuracy: 0.6000\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4851 - accuracy: 0.7667 - val_loss: 0.6834 - val_accuracy: 0.5500\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.6913 - accuracy: 0.6167 - val_loss: 0.6401 - val_accuracy: 0.6000\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.5751 - accuracy: 0.7333 - val_loss: 0.6292 - val_accuracy: 0.6500\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4552 - accuracy: 0.8333 - val_loss: 0.6213 - val_accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4711 - accuracy: 0.7833 - val_loss: 0.6283 - val_accuracy: 0.6500\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.4922 - accuracy: 0.8000 - val_loss: 0.6218 - val_accuracy: 0.8000\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4999 - accuracy: 0.7333 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.4142 - accuracy: 0.8333 - val_loss: 0.9638 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4997 - accuracy: 0.7833 - val_loss: 0.9467 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4471 - accuracy: 0.8000 - val_loss: 0.9215 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.3639 - accuracy: 0.8833 - val_loss: 1.0955 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4467 - accuracy: 0.7833 - val_loss: 1.4220 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3836 - accuracy: 0.8167 - val_loss: 1.3627 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.4409 - accuracy: 0.8167 - val_loss: 1.4982 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3847 - accuracy: 0.8667 - val_loss: 1.5508 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4509 - accuracy: 0.7667 - val_loss: 1.7877 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3911 - accuracy: 0.8667 - val_loss: 1.4661 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4155 - accuracy: 0.7833 - val_loss: 1.7057 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3841 - accuracy: 0.8167 - val_loss: 1.4569 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3656 - accuracy: 0.8500 - val_loss: 1.4357 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3197 - accuracy: 0.8500 - val_loss: 1.7411 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.2558 - accuracy: 0.9000 - val_loss: 1.7602 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.2463 - accuracy: 0.9000 - val_loss: 1.2605 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3363 - accuracy: 0.8833 - val_loss: 1.6812 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3243 - accuracy: 0.8667 - val_loss: 1.4264 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4650 - accuracy: 0.7500 - val_loss: 1.6816 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.3339 - accuracy: 0.8667 - val_loss: 1.1472 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3253 - accuracy: 0.8667 - val_loss: 1.1251 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.4691 - accuracy: 0.7167 - val_loss: 1.4116 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.2717 - accuracy: 0.8667 - val_loss: 1.1255 - val_accuracy: 0.5500\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.2588 - accuracy: 0.9000 - val_loss: 1.0587 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3394 - accuracy: 0.8333 - val_loss: 1.1530 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4258 - accuracy: 0.8167 - val_loss: 0.2595 - val_accuracy: 0.9500\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3136 - accuracy: 0.8333 - val_loss: 0.3606 - val_accuracy: 0.8000\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.2642 - accuracy: 0.9167 - val_loss: 1.4163 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4314 - accuracy: 0.7667 - val_loss: 1.3718 - val_accuracy: 0.5500\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.2637 - accuracy: 0.8833 - val_loss: 0.3371 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.3295 - accuracy: 0.8500 - val_loss: 0.6713 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3258 - accuracy: 0.8833 - val_loss: 0.9363 - val_accuracy: 0.5500\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.4043 - accuracy: 0.8000 - val_loss: 0.6510 - val_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3576 - accuracy: 0.8167 - val_loss: 0.2352 - val_accuracy: 0.9000\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.4384 - accuracy: 0.7833 - val_loss: 0.2094 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.2236 - accuracy: 0.9500 - val_loss: 1.0229 - val_accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.3872 - accuracy: 0.8333 - val_loss: 0.3472 - val_accuracy: 0.8000\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.3078 - accuracy: 0.9167 - val_loss: 0.4266 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.2580 - accuracy: 0.8667 - val_loss: 0.9434 - val_accuracy: 0.6000\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.3630 - accuracy: 0.8333 - val_loss: 0.6579 - val_accuracy: 0.6000\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3183 - accuracy: 0.8667 - val_loss: 0.2714 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.2230 - accuracy: 0.9667 - val_loss: 2.9015 - val_accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzPLrMBpnthJ",
        "outputId": "c076b986-7a81-44cf-e58d-ac372145d399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Plots a confussion matrix\n",
        "def plot_confusion_matrix(cm,\n",
        "                          classes, \n",
        "                          normalized=False, \n",
        "                          title=None, \n",
        "                          cmap=plt.cm.Blues,\n",
        "                          size=(10,10)):\n",
        "    fig, ax = plt.subplots(figsize=size)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalized else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "y_probs = model.predict(X_test, verbose=0)\n",
        "\n",
        "# Get predicted labels\n",
        "yhat_probs = np.argmax(y_probs, axis=1)\n",
        "y_trues = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "\n",
        "# Sets decimal precision (for printing output only)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Compute confusion matrix data\n",
        "cm = confusion_matrix(y_trues, yhat_probs)\n",
        "\n",
        "\n",
        "\n",
        "plot_confusion_matrix(cm,\n",
        "                          ['snoring','breathing'], \n",
        "                          normalized=False, \n",
        "                          title=\"Model Performance\", \n",
        "                          cmap=plt.cm.Blues,\n",
        "                          size=(4,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK0LVaVaqufg",
        "outputId": "171fea61-b3a2-4f1b-e7fb-9f4f925811c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "re = classification_report(y_trues, yhat_probs, labels=[0,1], target_names=['snoring','breathing'])\n",
        "\n",
        "print(re)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       1.00      0.20      0.33        10\n",
            "   breathing       0.56      1.00      0.71        10\n",
            "\n",
            "    accuracy                           0.60        20\n",
            "   macro avg       0.78      0.60      0.52        20\n",
            "weighted avg       0.78      0.60      0.52        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando CNN com SVC (o melhor modelo da etapa anterior):"
      ],
      "metadata": {
        "id": "Zoi17S2GAFAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ra1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i752j65AJeS",
        "outputId": "41030da8-86f4-4c65-aee6-bbd397f9a930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     snoring       0.75      1.00      0.86         9\n",
            "   breathing       1.00      0.73      0.84        11\n",
            "\n",
            "    accuracy                           0.85        20\n",
            "   macro avg       0.88      0.86      0.85        20\n",
            "weighted avg       0.89      0.85      0.85        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De modo geral o SVC obteve melhor desempenho que o CNN, mas ainda assim o resultado poderia ser muito melhor caso tivéssemos uma base maior e assim mais dados para treino."
      ],
      "metadata": {
        "id": "jNk20prL_mly"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQeO5p7bcL6M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coisas para refazer:  \n",
        "\n",
        "(Conjuntos de teste e treino deveriam ser os mesmos na CNN e no SVM e MLP. No SVM e MLP utilizei o train_test_split e na CNN fiz uma separação diferente.) Utilizar a separação feita na CNN, realizar o reshape e aplicar o SVM e MLP."
      ],
      "metadata": {
        "id": "QtWJpRsHfQDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1HevXPk1fVW0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}